[
  {
    "objectID": "Posts.html",
    "href": "Posts.html",
    "title": "Blog Posts",
    "section": "",
    "text": "Analyzing Ambient Air Quality Trends in Ghana\n\n\n\nColumbia University\n\n\nStats\n\n\nR\n\n\nHealth\n\n\n\nUsing data from a fleet of air pollution monitors to visualize patterns in community air quality levels and explore reasons for the pollution trends.\n\n\n\nLewis White\n\n\nFeb 25, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPreliminary Analysis of Heat’s Impact on Mental Health Among Pregnancy Cohort\n\n\n\nColumbia University\n\n\nStats\n\n\nR\n\n\nHealth\n\n\n\nThis analysis was included in a grant proposal that aims to further explore the impacts of temperature on mental health and test whether an intervention related to heat…\n\n\n\nLewis White\n\n\nJan 26, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRaking to Improve Survey Weights\n\n\n\nColumbia University\n\n\nR\n\n\nSurvey\n\n\n\nEmploying raking, also known as iterative proportional fitting, to refine survey weights and better align results with known population values.\n\n\n\nLewis White\n\n\nMay 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhose Song is it Anyway?\n\n\n\nMEDS\n\n\nR\n\n\nMachine Learning\n\n\n\nVisualizing my Spotify data and creating a model to determine whether a song comes from my library or my friend Elke’s.\n\n\n\nLewis White\n\n\nMar 12, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEthics of AI and Behavioral Nudging for the Environment\n\n\n\nMEDS\n\n\n\nA debate about how AI and nudge theory should or shouldn’t be used to tackle environmental problems.\n\n\n\nLewis White, Elke Windschitl\n\n\nJan 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModeling Asthma Hospitalizations\n\n\n\nMEDS\n\n\nR\n\n\nAsthma\n\n\n\nExploring factors that effect the hospitalization rate due to asthma in California counties.\n\n\n\nLewis White\n\n\nDec 3, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBehind the Scenes of Our LGBTQIA+ Pride Research\n\n\n\ndscout\n\n\nUX\n\n\n\nAn inside look at the methodology behind our qualitative research on LGBTQIA+ experiences with Pride—covering survey design, participant recruiting, thematic analysis, and…\n\n\n\nLewis White\n\n\nJun 25, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTesting How To Improve Video Response Quality in Remote Research\n\n\n\ndscout\n\n\nR\n\n\nUX\n\n\n\nUsing ANOVAs and t-tests to examine how specific instructions improve the quality of user-generated videos, helping researchers capture better insights while balancing…\n\n\n\nLewis White\n\n\nMay 1, 2022\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Lewis White",
    "section": "",
    "text": "I’m Lewis ~ welcome to my website!\nI recently graduated from the Bren School of Science & Management at UC Santa Barbara, where I received a Master’s Degree in Environmental Data Science.\nIn my spare time, you can find me hiking in the beautiful Santa Barbara hills, painting watercolor animals, or practicing my dinks on the pickleball court."
  },
  {
    "objectID": "index.html#hello",
    "href": "index.html#hello",
    "title": "Lewis White",
    "section": "",
    "text": "I’m Lewis ~ welcome to my website!\nI recently graduated from the Bren School of Science & Management at UC Santa Barbara, where I received a Master’s Degree in Environmental Data Science.\nIn my spare time, you can find me hiking in the beautiful Santa Barbara hills, painting watercolor animals, or practicing my dinks on the pickleball court."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Lewis White",
    "section": "Education",
    "text": "Education\nMaster of Environmental Data Science, 3.97 GPA (June 2023)\n\nBren School of Environmental Science & Management – University of California, Santa Barbara (UCSB)\n\nBachelor of Arts in Statistics and Psychology (Cum Laude), 3.71 GPA (June 2020)\n\nCarleton College, Northfield, MN"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Lewis White",
    "section": "Experience",
    "text": "Experience\nQualitative Research Advisor | dscout | 07/2020 - 07/2022\nAccount Management Intern | BBDO Worldwide | 06/2019 - 08/2019\nStatistical Consultant | Northfield City Council | 01/2018 - 03/2018"
  },
  {
    "objectID": "posts/2025-01-26-heat-stress/index.html",
    "href": "posts/2025-01-26-heat-stress/index.html",
    "title": "Preliminary Analysis of Heat’s Impact on Mental Health Among Pregnancy Cohort",
    "section": "",
    "text": "Pregnancy and the postpartum period can be an especially challenging time for women’s mental health—no matter where they live or what their circumstances are. In the U.S., around 13% of women experience perinatal depression [1]. However, in many lower-income settings, these numbers are much higher. In Ghana, for instance, perinatal depression has been reported in up to 50% of pregnancies, with 13–17% of women experiencing suicidal thoughts [2].\nRural areas, where healthcare services are often harder to access, seem to face the highest risks. Compounding the issue, Ghana (like much of sub-Saharan Africa) doesn’t have a routine screening protocol for perinatal depression and anxiety, leaving many cases undetected and untreated [3].\nMeanwhile, research in climate and health has increasingly shown that extreme temperatures can impact mental health [4]. Evidence suggests that heat exposure may trigger inflammation in the hypothalamic-pituitary-adrenal (HPA) axis—which plays a key role in managing the body’s response to stress—and that activation contributes to anxiety [5]."
  },
  {
    "objectID": "posts/2025-01-26-heat-stress/index.html#background",
    "href": "posts/2025-01-26-heat-stress/index.html#background",
    "title": "Preliminary Analysis of Heat’s Impact on Mental Health Among Pregnancy Cohort",
    "section": "",
    "text": "Pregnancy and the postpartum period can be an especially challenging time for women’s mental health—no matter where they live or what their circumstances are. In the U.S., around 13% of women experience perinatal depression [1]. However, in many lower-income settings, these numbers are much higher. In Ghana, for instance, perinatal depression has been reported in up to 50% of pregnancies, with 13–17% of women experiencing suicidal thoughts [2].\nRural areas, where healthcare services are often harder to access, seem to face the highest risks. Compounding the issue, Ghana (like much of sub-Saharan Africa) doesn’t have a routine screening protocol for perinatal depression and anxiety, leaving many cases undetected and untreated [3].\nMeanwhile, research in climate and health has increasingly shown that extreme temperatures can impact mental health [4]. Evidence suggests that heat exposure may trigger inflammation in the hypothalamic-pituitary-adrenal (HPA) axis—which plays a key role in managing the body’s response to stress—and that activation contributes to anxiety [5]."
  },
  {
    "objectID": "posts/2025-01-26-heat-stress/index.html#objectives",
    "href": "posts/2025-01-26-heat-stress/index.html#objectives",
    "title": "Preliminary Analysis of Heat’s Impact on Mental Health Among Pregnancy Cohort",
    "section": "Objectives",
    "text": "Objectives\nThe analysis described below was originally prepared for a grant proposal aiming to build on existing research that links heat exposure to mental health challenges. If this grant is funded, the project will investigate the causal impact of high temperatures on maternal mental health in Ghana, explore the underlying mechanisms (e.g. physiological or social), and pilot a heat warning system to assess whether targeted interventions can mitigate these risks.\nAs a starting point, I used data from an ongoing pregnancy cohort in rural Ghana to highlight existing associations between heat and mental health in our target population. My preliminary analysis emphasizes the need for further research in this area and sets the stage for a larger-scale project should the proposal move forward."
  },
  {
    "objectID": "posts/2025-01-26-heat-stress/index.html#data-used-in-analysis",
    "href": "posts/2025-01-26-heat-stress/index.html#data-used-in-analysis",
    "title": "Preliminary Analysis of Heat’s Impact on Mental Health Among Pregnancy Cohort",
    "section": "Data Used In Analysis",
    "text": "Data Used In Analysis\n\nPregnancy Cohort Data\nFor this analysis, I used data from the Ghana Randomized Air Pollution and Health Study (GRAPHS)—a pregnancy cohort from rural, agrarian communities that began recruitment in 2014 and includes years of follow-up data collection. Among its many measures, GRAPHS includes mental health assessments, as well as possible biological and social mechanisms contributing to mental health, such as sleep, comorbid diseases, and various health and demographic data.\nOf these measures, 3 stood out to my team as particularly well-suited for the grant proposal:\n\nPerceived Stress Scale (PSS)\nA holistic, self-reported measure of how much control individuals feel they have over their lives. In the GRAPHS cohort, this survey consists of four questions about the frequency of certain feelings or situations, and a total score is calculated based on the responses.\nSum Negative Domain Score (NDS)\nA measure centered on specific, stress-inducing life events (e.g., financial troubles, medical issues, etc.). Respondents self-reported which events they experienced and rated them as positive, negative, or neutral. Negative events were then summed across domains—financial, medical, and so on—to create the NDS. This approach allowed us to categorize pregnant women into three groups: low stress (NDS = 0–1), moderate stress (NDS = 3–5), and high stress (NDS &gt; 5).\nActigraphy for Sleep\nObjective sleep measurements were collected from participants wearing watch-like devices (actigraphs) to estimate rest/activity cycles. Data were gathered from 156 participants during both single-night and multi-night recordings at two follow-up periods (4 and 8 years postpartum).\n\nWe decided to focus on all three measures to gain a well-rounded perspective on maternal stress—looking at how women feel in general, what real-life stressors they face, and how well they’re sleeping. By combining these different angles, we can be more confident in our overall findings.\n\n\nTemperature Data\nI initially looked at four different heat metrics—Sea Surface Temperature, Heat Index, Wet Bulb Temperature, and Wet Bulb Globe Temperature (WBGT). I ultimately chose WBGT because it’s well-known for capturing not just temperature, but also humidity, wind speed, and solar radiation. Military agencies, OSHA, and other groups rely on WBGT for guidelines on safe activity levels.\nSince the grant zeroes in on high-heat events, I used daily maximum WBGT (derived from hourly readings) as the key measurement for this analysis."
  },
  {
    "objectID": "posts/2025-01-26-heat-stress/index.html#methods-of-analysis",
    "href": "posts/2025-01-26-heat-stress/index.html#methods-of-analysis",
    "title": "Preliminary Analysis of Heat’s Impact on Mental Health Among Pregnancy Cohort",
    "section": "Methods of Analysis",
    "text": "Methods of Analysis\nFor this preliminary analysis, I used a few different modeling approaches—distributed lag models (DLMs) and two types of regression—to explore how temperature exposure over time may impact mental health outcomes.\n\nDistributed Lag Models (DLMs): DLMs provide a flexible way to assess how temperature exposure at different points in time might influence stress levels. Instead of focusing on a single time window (e.g., just the day before the survey), DLMs capture both delayed and cumulative effects over the full 270-day pregnancy period. I started with this approach to get a clearer picture of how far back high temperatures might impact later mental health outcomes.\n\nThe sections below focus on the regression results, but for those interested, I’ve included the full DLM results and interpretations in the appendix.\nLinear Regression: Linear regression examines the relationship between a continuous predictor (like average WBGT) and a continuous outcome (such as the PSS-4 score). Based on initial results from the DLM, I looked at whether higher average WBGT in each trimester—or over the entire pregnancy—was linked to changes in stress levels or total sleep duration.\nOrdered Logistic Regression: Since the sample was divided into ordered stress categories (low, moderate, and high) based on the NDS score, ordered logistic regression helps estimate the odds of being in a higher stress category given temperature exposure."
  },
  {
    "objectID": "posts/2025-01-26-heat-stress/index.html#exploring-the-relationship-between-temperature-and-perceived-stress-pss",
    "href": "posts/2025-01-26-heat-stress/index.html#exploring-the-relationship-between-temperature-and-perceived-stress-pss",
    "title": "Preliminary Analysis of Heat’s Impact on Mental Health Among Pregnancy Cohort",
    "section": "Exploring the relationship between temperature and perceived stress (PSS)",
    "text": "Exploring the relationship between temperature and perceived stress (PSS)\n\nLinear Regression\nTo investigate the relationship between heat exposure (WBGT) and perceived stress scores (PSS-4) during pregnancy, I calculated trimester-specific daily maximum WBGT averages as well as the overall average of daily maximum WBGT for the entire pregnancy. For the third trimester and full pregnancy period, I restricted the WBGT averages to temperatures recorded up to the survey date to ensure alignment with the stress assessment period.\nAs described earlier, I used a linear regression model to assess the association between PSS-4 and WBGT for each time period. Initially, I included covariates such as demographic, socioeconomic, and physical health data, but these variables did not significantly contribute to the model or improve its overall quality. For simplicity, I excluded them from the final results presented in the grant proposal and this blog.\n\n\nCode\n## SET UP THE DATA -- find temps over custom periods of interest\n\n# Function to process temperature data for the selected metric\nprocess_temperature_data &lt;- function(era5_data, metric) {\n  era5_data %&gt;%\n    select(community, date, !!sym(metric)) %&gt;%\n    rename(temp_metric = !!sym(metric)) %&gt;%\n    distinct()\n}\n\n# Process temp data\ntemp_data_clean &lt;- process_temperature_data(era5_data = era5, metric = \"max_wbgt\")\n\n\ncalc_custom_temp_avg &lt;- function(stress_data, temp_data) {\n  stress_data %&gt;%\n    rowwise() %&gt;%  # Perform operations for each row (unique survey observation)\n    mutate(\n      # Temperature on the day of the survey\n      avg_temp_day_of_survey = temp_data %&gt;%\n        filter(community == vname, date == survey_date) %&gt;%\n        summarise(mean_temp = mean(temp_metric, na.rm = TRUE)) %&gt;%\n        pull(mean_temp),\n      \n      # Temperature the day before the survey\n      avg_temp_day_before_survey = temp_data %&gt;%\n        filter(community == vname, date == survey_date - 1) %&gt;%\n        summarise(mean_temp = mean(temp_metric, na.rm = TRUE)) %&gt;%\n        pull(mean_temp),\n      \n      # Average temperature for the week before the survey\n      avg_temp_week_before_survey = temp_data %&gt;%\n        filter(community == vname, date &gt;= survey_date - 7 & date &lt; survey_date) %&gt;%\n        summarise(mean_temp = mean(temp_metric, na.rm = TRUE)) %&gt;%\n        pull(mean_temp),\n      \n      # Average temperature for the 3 months before the survey\n      avg_temp_3_months_before = temp_data %&gt;%\n        filter(community == vname, date &gt;= survey_date - 90 & date &lt; survey_date) %&gt;%\n        summarise(mean_temp = mean(temp_metric, na.rm = TRUE)) %&gt;%\n        pull(mean_temp),\n      \n      # Average temperature for the 6 months before the survey\n      avg_temp_6_months_before = temp_data %&gt;%\n        filter(community == vname, date &gt;= survey_date - 180 & date &lt; survey_date) %&gt;%\n        summarise(mean_temp = mean(temp_metric, na.rm = TRUE)) %&gt;%\n        pull(mean_temp),\n      \n      ## TRIMESTER TEMP CALCULATIONS\n      # Estimate conception date (280 days before delivery)\n      \n      # Use gestational age if available, otherwise default to 280 - medical average (not our average) gestation period \n      gestage_days = ifelse(is.na(gestage_days), 280, gestage_days),\n      \n      # Calculate conception date based on gestational age\n      conception_date = datdeliv - gestage_days,\n  \n      # Pre-conception temperature average (60 days before conception)\n      avg_temp_pre_conception = temp_data %&gt;%\n        filter(\n          community == vname,\n          date &gt;= conception_date - 60 & date &lt; conception_date\n        ) %&gt;%\n        summarise(mean_temp = mean(temp_metric, na.rm = TRUE)) %&gt;%\n        pull(mean_temp),\n      \n      # First trimester temperature average\n      avg_temp_first_trimester = temp_data %&gt;%\n        filter(\n          community == vname,\n          date &gt;= conception_date & date &lt; conception_date + 90\n        ) %&gt;%\n        summarise(mean_temp = mean(temp_metric, na.rm = TRUE)) %&gt;%\n        pull(mean_temp),\n      \n      # Second trimester temperature average\n      avg_temp_second_trimester = temp_data %&gt;%\n        filter(\n          community == vname,\n          date &gt;= conception_date + 91 & date &lt; conception_date + 180\n        ) %&gt;%\n        summarise(mean_temp = mean(temp_metric, na.rm = TRUE)) %&gt;%\n        pull(mean_temp),\n      \n      # Third trimester temperature average\n      avg_temp_third_trimester = temp_data %&gt;%\n        filter(\n          community == vname,\n          date &gt;= conception_date + 181 & date &lt;= survey_date # only include up until the survey date\n        ) %&gt;%\n        summarise(mean_temp = mean(temp_metric, na.rm = TRUE)) %&gt;%\n        pull(mean_temp),\n     \n       # Average temperature across the entire pregnancy\n      avg_temp_entire_pregnancy = temp_data %&gt;%\n        filter(\n          community == vname,  \n          date &gt;= conception_date & date &lt;= survey_date  # Filter pregnancy period estimated as 280 days before delivery. Only include up until the survey date. \n        ) %&gt;%\n        summarise(mean_temp = mean(temp_metric, na.rm = TRUE)) %&gt;%\n        pull(mean_temp)  \n      \n    ) %&gt;%\n    ungroup()  # Remove row-wise grouping\n}\n\n# Add custom periods\npss_simple_custom_lags &lt;- calc_custom_temp_avg(stress_data = pss_simple, temp_data = temp_data_clean)\n\n\n\n\n# Rename variables in the dataset\npss_simple_custom_lags_renamed &lt;- pss_simple_custom_lags %&gt;%\n  rename(\n    `Average Temp Entire Pregnancy` = avg_temp_entire_pregnancy,\n    `Average Temp Pre-Conception` = avg_temp_pre_conception,\n    `Average Temp First Trimester` = avg_temp_first_trimester,\n    `Average Temp Second Trimester` = avg_temp_second_trimester,\n    `Average Temp Third Trimester` = avg_temp_third_trimester\n  ) %&gt;%\n  rename(`Number of Lifetime Pregnancies` = pregchn)\n\n# Define models for PSS4\nWBGT_daily_max_models_pss_renamed &lt;- list(\n  lm(PSS4 ~ `Average Temp Entire Pregnancy`, data = pss_simple_custom_lags_renamed),\n  lm(PSS4 ~ `Average Temp Pre-Conception`, data = pss_simple_custom_lags_renamed),\n  lm(PSS4 ~ `Average Temp First Trimester`, data = pss_simple_custom_lags_renamed),\n  lm(PSS4 ~ `Average Temp Second Trimester`, data = pss_simple_custom_lags_renamed),\n  lm(PSS4 ~ `Average Temp Third Trimester`, data = pss_simple_custom_lags_renamed)\n)\n# Display model summaries for PSS4\nstargazer(WBGT_daily_max_models_pss_renamed, type = \"text\", title = \"Regression Results: PSS vs. WBGT Temperatures\",\n          column.labels = c(\"Entire Pregnancy\", \n                            \"Pre-Conception\", \n                            \"First Trimester\", \n                            \"Second Trimester\", \n                            \"Third Trimester\"),\n          dep.var.labels = \"Perceived Stress Score\", \n          omit.stat = c(\"f\", \"ser\"), \n          no.space = TRUE, digits = 2,\n          star.cutoffs = c(0.05, 0.01, 0.001)) # Custom significance levels)\n\n\n\nRegression Results: PSS vs. WBGT Temperatures\n================================================================================================================\n                                                              Dependent variable:                               \n                                --------------------------------------------------------------------------------\n                                                             Perceived Stress Score                             \n                                Entire Pregnancy Pre-Conception First Trimester Second Trimester Third Trimester\n                                      (1)             (2)             (3)             (4)              (5)      \n----------------------------------------------------------------------------------------------------------------\n`Average Temp Entire Pregnancy`      0.87**                                                                     \n                                     (0.28)                                                                     \n`Average Temp Pre-Conception`                        -0.13                                                      \n                                                     (0.15)                                                     \n`Average Temp First Trimester`                                      0.47**                                      \n                                                                    (0.15)                                      \n`Average Temp Second Trimester`                                                     0.59***                     \n                                                                                     (0.17)                     \n`Average Temp Third Trimester`                                                                        -0.02     \n                                                                                                     (0.21)     \nConstant                            -17.20*          10.15*          -6.48           -9.43*           6.90      \n                                     (7.50)          (3.99)         (4.11)           (4.52)          (5.59)     \n----------------------------------------------------------------------------------------------------------------\nObservations                          428             428             428             428              428      \nR2                                    0.02           0.002           0.02             0.03           0.0000     \nAdjusted R2                           0.02          -0.0004          0.02             0.03           -0.002     \n================================================================================================================\nNote:                                                                              *p&lt;0.05; **p&lt;0.01; ***p&lt;0.001\n\n\nThe results indicate that:\n\nElevated heat exposure during the entire pregnancy is significantly associated with elevated perceived stress levels. For every 1°C increase in the average daily maximum WBGT, our model predicts that the perceived stress score would increase on average by 0.87 (p &lt; 0.01).\nHigher average daily maximum WBGT during the first trimester (β = 0.47, p &lt; 0.01) and second trimester (β = 0.59, p &lt; 0.001) are both significantly associated with increased PSS-4 scores. \nThe third trimester average showed no significant effect, suggesting that elevated temperatures closer to the survey date are less strongly linked to stress levels.\nHigher WBGT during the preconception period is associated with a slight, insignificant reduction in PSS-4 scores."
  },
  {
    "objectID": "posts/2025-01-26-heat-stress/index.html#exploring-the-relationship-between-temperature-and-sum-nds-category",
    "href": "posts/2025-01-26-heat-stress/index.html#exploring-the-relationship-between-temperature-and-sum-nds-category",
    "title": "Preliminary Analysis of Heat’s Impact on Mental Health Among Pregnancy Cohort",
    "section": "Exploring the relationship between temperature and sum NDS category",
    "text": "Exploring the relationship between temperature and sum NDS category\n\nOrdered Logistic Regression\nTo further explore the link between heat stress and mental health during pregnancy, I calculated trimester-specific averages of daily maximum WBGT as well as the overall average of daily maximum WBGT for the full pregnancy period. As mentioned earlier, I used ordered logistic regression to assess the association between Sum NDS Category and WBGT averages, since Sum NDS is a categorical variable with a natural order (low, moderate, and high stress).\n\n\nCode\ncalc_custom_temp_avg &lt;- function(stress_data, temp_data, metric) {\n  stress_data %&gt;%\n    rowwise() %&gt;%\n    mutate(\n      # Temperature on the day of the survey\n      avg_temp_day_of_survey = temp_data %&gt;%\n        filter(community == vname, date == survey_date) %&gt;%\n        summarise(mean_temp = mean(!!sym(metric), na.rm = TRUE)) %&gt;%\n        pull(mean_temp),\n      \n      # Temperature the day before the survey\n      avg_temp_day_before_survey = temp_data %&gt;%\n        filter(community == vname, date == survey_date - 1) %&gt;%\n        summarise(mean_temp = mean(!!sym(metric), na.rm = TRUE)) %&gt;%\n        pull(mean_temp),\n      \n      # Average temperature for the week before the survey\n      avg_temp_week_before_survey = temp_data %&gt;%\n        filter(community == vname, date &gt;= survey_date - 7 & date &lt; survey_date) %&gt;%\n        summarise(mean_temp = mean(!!sym(metric), na.rm = TRUE)) %&gt;%\n        pull(mean_temp),\n      \n       # Average temperature for the month before the survey\n      avg_temp_month_before_survey = temp_data %&gt;%\n        filter(community == vname, date &gt;= survey_date - 30 & date &lt; survey_date) %&gt;%\n        summarise(mean_temp = mean(!!sym(metric), na.rm = TRUE)) %&gt;%\n        pull(mean_temp),\n      \n      # Average temperature for the 3 months before the survey\n      avg_temp_3_months_before = temp_data %&gt;%\n        filter(community == vname, date &gt;= survey_date - 90 & date &lt; survey_date) %&gt;%\n        summarise(mean_temp = mean(!!sym(metric), na.rm = TRUE)) %&gt;%\n        pull(mean_temp),\n      \n      # Average temperature for the 6 months before the survey\n      avg_temp_6_months_before = temp_data %&gt;%\n        filter(community == vname, date &gt;= survey_date - 180 & date &lt; survey_date) %&gt;%\n        summarise(mean_temp = mean(!!sym(metric), na.rm = TRUE)) %&gt;%\n        pull(mean_temp),\n      \n      ## TRIMESTER TEMP CALCULATIONS\n      # Estimate conception date (280 days before delivery)\n      \n      # Use gestational age if available, otherwise default to 280 - medical average (not our average) gestation period \n      gestage_days = ifelse(is.na(gestage_days), 280, gestage_days),\n      \n      # Calculate conception date based on gestational age\n      conception_date = datdeliv - gestage_days,\n  \n      # Pre-conception temperature average (60 days before conception)\n      avg_temp_pre_conception = temp_data %&gt;%\n        filter(\n          community == vname,\n          date &gt;= conception_date - 60 & date &lt; conception_date\n        ) %&gt;%\n        summarise(mean_temp = mean(!!sym(metric), na.rm = TRUE)) %&gt;%\n        pull(mean_temp),\n      \n      # First trimester temperature average\n      avg_temp_first_trimester = temp_data %&gt;%\n        filter(\n          community == vname,\n          date &gt;= conception_date & date &lt; conception_date + 90\n        ) %&gt;%\n        summarise(mean_temp = mean(!!sym(metric), na.rm = TRUE)) %&gt;%\n        pull(mean_temp),\n      \n      # Second trimester temperature average\n      avg_temp_second_trimester = temp_data %&gt;%\n        filter(\n          community == vname,\n          date &gt;= conception_date + 91 & date &lt; conception_date + 180\n        ) %&gt;%\n        summarise(mean_temp = mean(!!sym(metric), na.rm = TRUE)) %&gt;%\n        pull(mean_temp),\n      \n      # Third trimester temperature average\n      avg_temp_third_trimester = temp_data %&gt;%\n        filter(\n          community == vname,\n          date &gt;= conception_date + 181 & date &lt;= survey_date\n        ) %&gt;%\n        summarise(mean_temp = mean(!!sym(metric), na.rm = TRUE)) %&gt;%\n        pull(mean_temp),\n      \n      # Average temperature across the entire pregnancy\n      avg_temp_entire_pregnancy = temp_data %&gt;%\n        filter(\n          community == vname,\n          date &gt;= conception_date & date &lt;= survey_date\n        ) %&gt;%\n        summarise(mean_temp = mean(!!sym(metric), na.rm = TRUE)) %&gt;%\n        pull(mean_temp)\n    ) %&gt;%\n    ungroup()\n}\n\n\n\n\nmetrics &lt;- \"max_wbgt\"\n\n# Initialize an empty list to store results\nregression_results_polr &lt;- list()\n\n# Loop through each metric\nfor (metric in metrics) {\n  \n  # Calculate custom temperature averages\n  stress_data_with_temp &lt;- calc_custom_temp_avg(crisis_simple, era5, metric)\n  \n  # Fit ordered logistic regressions for the metric\n  models &lt;- list(\n    polr(formula = sum_nds_category ~ avg_temp_day_of_survey, data = stress_data_with_temp, method = \"logistic\"),\n    polr(formula = sum_nds_category ~ avg_temp_day_before_survey, data = stress_data_with_temp, method = \"logistic\"),\n    polr(formula = sum_nds_category ~ avg_temp_week_before_survey, data = stress_data_with_temp, method = \"logistic\"),\n    polr(formula = sum_nds_category ~ avg_temp_month_before_survey, data = stress_data_with_temp, method = \"logistic\"),\n    polr(formula = sum_nds_category ~ avg_temp_3_months_before, data = stress_data_with_temp, method = \"logistic\"),\n    polr(formula = sum_nds_category ~ avg_temp_6_months_before, data = stress_data_with_temp, method = \"logistic\")\n  )\n  \n  # Save results for the current metric\n  regression_results_polr[[metric]] &lt;- models\n}\n\n\n# List to store regression results and p-values\nregression_results &lt;- list()\n\n# Loop through each metric\nfor (metric in metrics) {\n  \n  # Calculate custom temperature averages\n  stress_data_with_temp &lt;- calc_custom_temp_avg(crisis_simple, era5, metric)\n  \n  # Fit models (6 regressions for survey date, 5 for pregnancy period)\n  models &lt;- list(\n    # polr(formula = sum_nds_category ~ avg_temp_day_of_survey, data = stress_data_with_temp, method = \"logistic\"),\n    # polr(formula = sum_nds_category ~ avg_temp_day_before_survey, data = stress_data_with_temp, method = \"logistic\"),\n    # polr(formula = sum_nds_category ~ avg_temp_week_before_survey, data = stress_data_with_temp, method = \"logistic\"),\n    # polr(formula = sum_nds_category ~ avg_temp_month_before_survey, data = stress_data_with_temp, method = \"logistic\"),\n    # polr(formula = sum_nds_category ~ avg_temp_3_months_before, data = stress_data_with_temp, method = \"logistic\"),\n    # polr(formula = sum_nds_category ~ avg_temp_6_months_before, data = stress_data_with_temp, method = \"logistic\"),\n    polr(formula = sum_nds_category ~ avg_temp_pre_conception, data = stress_data_with_temp, method = \"logistic\"),\n    polr(formula = sum_nds_category ~ avg_temp_first_trimester, data = stress_data_with_temp, method = \"logistic\"),\n    polr(formula = sum_nds_category ~ avg_temp_second_trimester, data = stress_data_with_temp, method = \"logistic\"),\n    polr(formula = sum_nds_category ~ avg_temp_third_trimester, data = stress_data_with_temp, method = \"logistic\"),\n    polr(formula = sum_nds_category ~ avg_temp_entire_pregnancy, data = stress_data_with_temp, method = \"logistic\")\n  )\n  \n  # Extract coefficients and p-values for each model\n  model_results &lt;- lapply(models, function(model) {\n    ctable &lt;- coef(summary(model))  # Extract coefficients and standard errors\n    p_values &lt;- pnorm(abs(ctable[, \"t value\"]), lower.tail = FALSE) * 2  # Calculate p-values\n    result &lt;- data.frame(Coefficient = ctable[, \"Value\"], `Std. Error` = ctable[, \"Std. Error\"], \n                         `t Value` = ctable[, \"t value\"], `p Value` = p_values)\n    return(result)\n  })\n  \n  # Store results for the current metric\n  regression_results[[metric]] &lt;- model_results\n}\n\n\n# Combine results into a single data frame for easier reporting\nformatted_results &lt;- lapply(names(regression_results), function(metric) {\n  data &lt;- regression_results[[metric]]\n  model_names &lt;- c(#\"Day of Survey\", \n                   # \"Day Before Survey\", \n                   # \"Week Before Survey\", \n                   # \"Month Before Survey\", \n                   # \"3 Months Before\", \n                   # \"6 Months Before\", \n                   \"Pre-Conception\", \n                   \"First Trimester\", \n                   \"Second Trimester\", \n                   \"Third Trimester\", \n                   \"Entire Pregnancy\")\n  data &lt;- lapply(seq_along(data), function(i) cbind(Model = model_names[i], data[[i]]))\n  data &lt;- do.call(rbind, data)\n  cbind(Metric = metric, data)\n})\n\n# Combine all metrics into a single data frame\nfinal_results &lt;- do.call(rbind, formatted_results)\n\n# Convert row names to a column\nfinal_results &lt;- tibble::rownames_to_column(final_results, var = \"regression_part\")\n\noptions(scipen=999)\n\n# Filter out rows with \"low|moderate\" or \"moderate|high1\"\nfiltered_results &lt;- final_results %&gt;%\n  filter(!grepl(\"low\\\\|moderate\", regression_part)) %&gt;%\n  filter(!grepl(\"moderate\\\\|high\", regression_part)) %&gt;%\n  filter(str_detect(regression_part, \"avg_temp\")) %&gt;%\n  \n  # add exponentiated coefficient for intepretation of 1 degree increase in temp\n  mutate(odds_ratio = exp(Coefficient)) %&gt;%\n\n  # add significant indicator\n  mutate(significant = ifelse(p.Value &lt; 0.05, 1, 0)) \n\n\nfiltered_results %&gt;% \n  select(Model, Coefficient, Std..Error, odds_ratio, p.Value) %&gt;%\n  rename(\n    `Model` = Model,\n    `Coefficient` = Coefficient,\n    `Std. Error` = Std..Error,\n    `Odds Ratio` = odds_ratio,\n    `P-Value` = p.Value\n  ) %&gt;%\n  gt() %&gt;%\n  fmt_number(\n    columns = c(`Coefficient`, `Std. Error`, `Odds Ratio`, `P-Value`),\n    decimals = 3\n  ) %&gt;%\n  tab_header(\n    title = \"Ordered Logistic Regression Results\",\n    subtitle = \"Higher WBGT during pre-conception, the first trimester, and the entire pregnancy period as a whole associated with increased likelihood of belonging to a higher stress group.\"\n  ) %&gt;%\n  cols_align(\n    align = \"center\"\n  )\n\n\n\n\n\n\n\n\n\nOrdered Logistic Regression Results\n\n\nHigher WBGT during pre-conception, the first trimester, and the entire pregnancy period as a whole associated with increased likelihood of belonging to a higher stress group.\n\n\nModel\nCoefficient\nStd. Error\nOdds Ratio\nP-Value\n\n\n\n\nPre-Conception\n0.176\n0.085\n1.193\n0.038\n\n\nFirst Trimester\n0.301\n0.096\n1.351\n0.002\n\n\nSecond Trimester\n0.165\n0.092\n1.179\n0.072\n\n\nThird Trimester\n−0.003\n0.086\n0.997\n0.976\n\n\nEntire Pregnancy\n0.443\n0.153\n1.557\n0.004\n\n\n\n\n\n\n\n\nThe results indicate that:\n\nAgain, heat stress during the entire pregnancy is significantly associated with belonging to a higher stress group. A °1C increase in WBGT is associated with a 55.7% increase in the odds of belonging to a higher stress group (p = 0.004).\nHigher daily maximum WBGT during the preconception period and first trimester is significantly associated with an increased likelihood of belonging to a higher stress group. A 1°C increase in WBGT is linked to a 19.3% increase in the odds of higher stress during pre-conception (p = 0.038) and a 35.1% increase during the first trimester (p = 0.002).\nThe second trimester showed a positive association between WBGT and Sum NDS Category, but the effect was not statistically significant.\nThe third trimester showed no association between WBGT and Sum NDS Category, suggesting that temperatures closer to the survey date are less strongly linked to stress levels."
  },
  {
    "objectID": "posts/2025-01-26-heat-stress/index.html#exploring-the-relationship-between-temperature-and-sleep-quantity",
    "href": "posts/2025-01-26-heat-stress/index.html#exploring-the-relationship-between-temperature-and-sleep-quantity",
    "title": "Preliminary Analysis of Heat’s Impact on Mental Health Among Pregnancy Cohort",
    "section": "Exploring the relationship between temperature and sleep quantity",
    "text": "Exploring the relationship between temperature and sleep quantity\nA linear regression model was employed to examine the association between average WBGT and total sleep time (TST), providing insights into the impact of heat on sleep quantity.\n\n\nCode\nactigraphy_with_temp &lt;- actigraphy_simple_full %&gt;%\n  rowwise() %&gt;%  # Process each row individually\n  mutate(\n    avg_temp = WBGT_daily_max %&gt;%\n      filter(\n        community == vname,  # Match the community\n        date &gt;= Start.Date & date &lt;= End.Date  # Filter by date range\n      ) %&gt;%\n      summarise(mean_temp = mean(max_wbgt, na.rm = TRUE)) %&gt;%  # Calculate mean temperature between the start date and end date (for just one night study, this would be a two day average)\n      pull(mean_temp)  # Extract the mean value\n  ) %&gt;%\n  ungroup() %&gt;% # Remove row-wise grouping \n  filter(!is.na(avg_temp)) # remove NA community or participants where no temp data for community\n\n# After removing 7 participants who did not have a community that matches the communities in the temperature data, we are left with 177 participants. \n\n\n\nactigraphy_with_temp_no_outlier &lt;- actigraphy_with_temp %&gt;%\n  filter(avg_temp &gt; 20) # One temperature recording (18.7) is over 4 degrees colder than the next coolest temperature (22.9) -- this point was found to be extremely high leverage as well as an outlier. There is not evidence that this is an erroneous reading, but for the purposes of creating a reliable model, the value was removed. \n\n\n# Fit a linear model\nsleep_time_model_no_outlier &lt;- lm(Sleep.Time..mins. ~ avg_temp, data = actigraphy_with_temp_no_outlier)\n\n\n# Extract model summary statistics\nsummary_sleep_time &lt;- summary(sleep_time_model_no_outlier)\nslope &lt;- round(coef(summary_sleep_time)[\"avg_temp\", \"Estimate\"], 2)\np_value &lt;- signif(coef(summary_sleep_time)[\"avg_temp\", \"Pr(&gt;|t|)\"], 2)\nr_squared &lt;- round(summary_sleep_time$r.squared, 2)\nn &lt;- nrow(actigraphy_with_temp_no_outlier)\n\n# Create the plot\nactigraphy_with_temp_no_outlier %&gt;%\n  ggplot(aes(x = avg_temp, y = Sleep.Time..mins.)) +\n  geom_point(alpha = 0.6) + \n  geom_smooth(method = \"lm\") +\n  theme_classic(base_size = 15) + # Increase base text size\n  labs(\n    x = \"Average Daily Maximum WBGT Over Study Period\",\n    y = \"Total Sleep Time (mins)\",\n    title = \"Higher Temperatures Associated with Reduced \\nTotal Sleep Time\" # \n  ) +\n  theme(\n    plot.title = element_text(size = 16), # Adjust title size and style\n    axis.title.x = element_text(size = 14), # Adjust x-axis label size\n    axis.title.y = element_text(size = 14), # Adjust y-axis label size\n    axis.text = element_text(size = 12) # Adjust axis text size\n  ) +\n  annotate(\n    \"text\",\n    x = min(actigraphy_with_temp_no_outlier$avg_temp) + 0.5, \n    y = 220, \n    label = paste(\n      \"Slope =\", slope, \n      \"\\nP =\", p_value,\n      \"\\nR² =\", r_squared, \n      \"\\nN =\", n\n    ),\n    hjust = 0.4, \n    vjust = 0.5, \n    size = 4\n  )\n\n\n\n\n\n\n\n\n\nA highly significant negative association is observed, with a slope of -13.75 (p &lt; 0.001), indicating that for each degree increase in the average maximum WBGT, our model predicts that total sleep time decreases by approximately 14 minutes. These findings suggest that higher temperatures during the study period are associated with reduced total sleep duration, which may reflect the challenges of maintaining optimal sleep in warmer conditions."
  },
  {
    "objectID": "posts/2025-01-26-heat-stress/index.html#key-takeaways",
    "href": "posts/2025-01-26-heat-stress/index.html#key-takeaways",
    "title": "Preliminary Analysis of Heat’s Impact on Mental Health Among Pregnancy Cohort",
    "section": "Key Takeaways",
    "text": "Key Takeaways\nIt’s important to note these findings are from early-stage analyses using observational data. While the results strongly hint at an association between heat exposure and mental health outcomes, further work is needed to definitively establish causality. That said, here are a few takeaways I’d like to highlight.\n\nHeat Stress and Mental Health:\nAcross multiple modeling approaches (Distributed Lag Models, Linear Regression, and Ordered Logistic Regression), the findings consistently point toward higher heat exposures (measured via WBGT) being associated with elevated stress levels among pregnant women in rural Ghana.\nCritical Windows During Pregnancy:\nExposure to high temperatures early in pregnancy—especially during the first trimester—had the strongest association with negative mental health outcomes. This suggests that heat stress may have a greater impact in the early stages of gestation, with its effects diminishing later in pregnancy. If these findings hold, interventions like cooling strategies may be most valuable during the first trimester, when the risk appears to be highest.\nSleep Disruption:\nPreliminary linear regressions on actigraphy data suggest a significant negative relationship between temperature and total sleep time, with about 14 fewer minutes of sleep predicted for each 1°C increase in average maximum WBGT. This aligns with existing literature on heat-related sleep disturbances and may partially explain how temperature influences stress pathways."
  },
  {
    "objectID": "posts/2025-01-26-heat-stress/index.html#next-steps",
    "href": "posts/2025-01-26-heat-stress/index.html#next-steps",
    "title": "Preliminary Analysis of Heat’s Impact on Mental Health Among Pregnancy Cohort",
    "section": "Next Steps",
    "text": "Next Steps\nI am now starting to work on diving deeper into the causal framework through mediation analysis in R. This analysis aims to tease out how various mechanisms—such as changes in sleep, underlying physiological processes, and additional environmental factors (e.g. air pollution)—may mediate the relationship between temperature and maternal mental health."
  },
  {
    "objectID": "posts/2025-01-26-heat-stress/index.html#references",
    "href": "posts/2025-01-26-heat-stress/index.html#references",
    "title": "Preliminary Analysis of Heat’s Impact on Mental Health Among Pregnancy Cohort",
    "section": "References",
    "text": "References\n[1] Dagher, R. K., Bruckheim, H. E., Colpe, L. J., Edwards, E., & White, D. B. (2021). Perinatal Depression: Challenges and Opportunities. Journal of Women’s Health, 30(2), 154–159. https://doi.org/10.1089/jwh.2020.8862\n[2] WHO-Ghana. Strengthening Maternal Mental Health in Ghana - Policy Brief [Internet]. 2024. Available from: https://www.afro.who.int/sites/default/files/2024-02/Policy%20brief%20-%20Strengthening%20Maternal%20Mental%20Health%20in%20Ghana.pdf\n[3] McCauley, M., Brown, A., Ofosu, B., & van den Broek, N. (2019). “I just wish it becomes part of routine care”: Healthcare providers’ knowledge, attitudes and perceptions of screening for maternal mental health during and after pregnancy: a qualitative study. BMC Psychiatry, 19(1), 279. https://doi.org/10.1186/s12888-019-2261-x\n[4] Thompson, R., Hornigold, R., Page, L., & Waite, T. (2018). Associations between high ambient temperatures and heat waves with mental health outcomes: A systematic review. Public Health, 161, 171–191. https://doi.org/10.1016/j.puhe.2018.06.008\n[5] Fang, W., Liu, L., Yin, B., Ke, L., Su, Y., Liu, F., Ma, X., & Di, Q. (2023). Heat exposure intervention, anxiety level, and multi-omic profiles: A randomized crossover study. Environment International, 181, 108247. https://doi.org/10.1016/j.envint.2023.108247"
  },
  {
    "objectID": "posts/2025-01-26-heat-stress/index.html#appendix",
    "href": "posts/2025-01-26-heat-stress/index.html#appendix",
    "title": "Preliminary Analysis of Heat’s Impact on Mental Health Among Pregnancy Cohort",
    "section": "Appendix",
    "text": "Appendix\n\nDistributed Lag Model for PSS\nPredictions were generated relative to the median temperature (27.3°C) to evaluate how temperature and lagged exposure impact perceived stress levels. Due to the limited number of recordings below 24°C, and given the grant’s focus on heat exposure, I restricted the analysis to higher temperature ranges.\n\n\nCode\n# DLMs\n\n## SET UP THE DATA FOR DLNM\n\n# Function to process temperature data for the selected metric\nprocess_temperature_data &lt;- function(era5_data, metric) {\n  era5_data %&gt;%\n    select(community, date, !!sym(metric)) %&gt;%\n    rename(temp_metric = !!sym(metric)) %&gt;%\n    distinct()\n}\n\n# Function to create temperature lags\ncreate_temperature_lags &lt;- function(stress_data, temp_data) {\n  stress_data %&gt;%\n    select(mstudyid, vname, survey_date) %&gt;%\n    mutate(start_date = survey_date - 270) %&gt;%\n    rowwise() %&gt;%\n    mutate(lag_dates = list(seq.Date(start_date, survey_date, by = \"day\"))) %&gt;%\n    unnest(lag_dates) %&gt;%\n    rename(date = lag_dates) %&gt;%\n    left_join(temp_data, by = c(\"vname\" = \"community\", \"date\" = \"date\"))\n}\n\n# Process temp data\ntemp_data_clean &lt;- process_temperature_data(era5_data = era5, metric = \"max_wbgt\")\n\n# created lagged data set\ntemperature_lags &lt;- create_temperature_lags(stress_data = pss_simple, temp_data = temp_data_clean)\n\n# create wide-format lagged data\ntemperature_lags_wide &lt;- temperature_lags %&gt;%\n  mutate(lag = as.numeric(survey_date - date)) %&gt;%\n  pivot_wider(names_from = lag, values_from = temp_metric, names_prefix = \"temp_lag_\") %&gt;%\n  select(mstudyid, survey_date, starts_with(\"temp_lag_\")) %&gt;%\n  group_by(mstudyid, survey_date) %&gt;%\n  reframe(across(starts_with(\"temp_lag_\"), ~ first(na.omit(.)), .names = \"{col}\")) %&gt;%\n  left_join(pss_simple %&gt;% select(mstudyid, survey_date, PSS4), by = c(\"mstudyid\", \"survey_date\")) %&gt;%\n  filter(!is.na(temp_lag_0)) # Remove rows without lag 0 data\n\n# create temperature matrix for cross basis\ntemp_data_matrix &lt;- temperature_lags_wide %&gt;%\n  select(starts_with(\"temp_lag_\")) %&gt;%\n  as.matrix()\n\n## SET UP PARAMS\n\n# predictor DLNM model parameters -- captures the relationship between the predictor variable (temp) and the outcome\nvar_arg = list(fun = \"bs\", df = 4, degree = 3) # smooth cubic polynomial (degree = 3) between the boundary knots (no internal knots)\n\n# lag DLNM model parameters -- captures the lagged effects of the predictor variable (temp) over time.\nlag_arg = list(fun = \"bs\", df = 4, degree = 3) # smooth cubic polynomial (degree = 3) between the boundary knots (no internal knots)\n\n# cross-basis matrix for DLNM\ncb = crossbasis(temp_data_matrix, lag = c(1, ncol(temp_data_matrix)), argvar = var_arg, arglag = lag_arg) # basis for the predictor and lag \n\n\n\n\n## FIT MODEL\nmodel = glm(formula = PSS4 ~ cb, data = temperature_lags_wide, family = \"gaussian\") # stress scores continuous and normally dist, so gaussian family appropriate\n\n\n# GET PREDICTIONS (in reference to median temp)\ntemp_median &lt;- round(median(as.vector(temp_data_matrix)), 1) # centering value (median). \npss_temp_median &lt;- temp_median\n\n# generate predictions for a DLNM, set centering value as the median of all temperatures\ncpred = crosspred(cb, \n                  model, \n                  ci.level = 0.95, # 95% confidence intervals calculated around predicted values\n                  cen = temp_median, # predictions are relative to this baseline temperature.\n                  by = 0.1) # predictions are generated at intervals of 0.1 units of temperature\n\n\n# plot contour map of 3d plot\nplot(\n  cpred, \n  \"contour\", \n  main = paste0(\"Effects of Temperature and Lag on PSS Relative to \\nMedian Temperature (\", pss_temp_median, \"\\u00B0 C)\"), \n  xlab = \"Temperature (°C)\", \n  ylab = \"Lag (days)\", \n  key.title = title(main = \"Change \\nin PSS\", cex.main = 0.8)\n)\n\n\n\n\n\n\n\n\n\nCode\n# Examine lag effect at top percentile \ntemp_99.9pct = round(quantile(as.vector(temp_data_matrix), 0.999), 1) # third quartile of temperature\ntemp_99.9pct = as.numeric(temp_99.9pct)\npss_temp_99.9pct &lt;- temp_99.9pct\n\n\n## Customized plot of effect at top percentile \nplot_var = temp_99.9pct\nplot_var_matfit = cpred$matfit[rownames(cpred$matfit) == plot_var, ]\nnames(plot_var_matfit) = sub(\"lag\", \"\", names(plot_var_matfit))\nplot_var_matlow = cpred$matlow[rownames(cpred$matlow) == plot_var, ]\nnames(plot_var_matlow) = sub(\"lag\", \"\", names(plot_var_matlow))\nplot_var_mathigh = cpred$mathigh[rownames(cpred$mathigh) == plot_var, ]\nnames(plot_var_mathigh) = sub(\"lag\", \"\", names(plot_var_mathigh))\n\nplot(x = names(plot_var_matfit),\n       y = plot_var_matfit,\n       xlab = \"Lag (days)\", ylab = \"Effect on Perceived Stress Score (PSS)\",\n       main = paste0(\"At the 99.9th Temperature Percentile (\", temp_99.9pct,\"\\u00B0 C), \\nthe Effect of Temperature is Signficant for Lags 110-158\"),\n       type = \"l\", lwd = 2, ylim = c(min(plot_var_matlow), max(plot_var_mathigh)))  # plot of effect size at exposure/variable relative to median 26\n\npolygon(x = c(names(plot_var_mathigh),\n              rev(names(plot_var_matlow))),\n        y = c(plot_var_mathigh,\n                rev(plot_var_matlow)),\n        col = rgb(0, 0, 0, alpha = 0.2), border = NA)  # add confidence interval of OR at exposure/variable = 27.8\n\nabline(h = 0, lty = 2) # add line at effect size = 0\n\n\n\n\n\n\n\n\n\nThe plots above illustrate the association between temperature and PSS across various lag periods. Compared to the median temperature (27.3°C), extreme heat exposure (above 31°C) is associated with higher stress scores, particularly 4–5 months before the survey date. However, at both longer (9 months before) and shorter lag periods (a few weeks before the survey), these extremely high temperatures show a slight but non-significant mitigating effect, with stress scores decreasing relative to the median temperature.\n\n\n\nDistributed Lag Model for Sum NDS\nPredictions were generated relative to the median temperature (27.4°C) to assess how temperature and lagged exposure impact resilience, as measured by Sum NDS Category. As with the PSS analysis, the small number of recordings below 24°C and the grant’s focus on heat exposure led me to concentrate exclusively on higher temperatures.\n\n\nCode\n# Function to process temperature data for the selected metric\nprocess_temperature_data &lt;- function(era5_data, metric) {\n  era5_data %&gt;%\n    select(community, date, !!sym(metric)) %&gt;%\n    rename(temp_metric = !!sym(metric)) %&gt;%\n    distinct()\n}\n\n# Function to create temperature lags\ncreate_temperature_lags &lt;- function(stress_data, temp_data) {\n  stress_data %&gt;%\n    select(mstudyid, vname, survey_date) %&gt;%\n    mutate(start_date = survey_date - 270) %&gt;%\n    rowwise() %&gt;%\n    mutate(lag_dates = list(seq.Date(start_date, survey_date, by = \"day\"))) %&gt;%\n    unnest(lag_dates) %&gt;%\n    rename(date = lag_dates) %&gt;%\n    left_join(temp_data, by = c(\"vname\" = \"community\", \"date\" = \"date\"))\n}\n\n# Process temp data\ntemp_data_clean &lt;- process_temperature_data(era5_data = era5, metric = \"max_wbgt\")\n\n# created lagged data set\ntemperature_lags &lt;- create_temperature_lags(stress_data = crisis_simple, temp_data = temp_data_clean)\n\n# create wide-format lagged data\ntemperature_lags_wide &lt;- temperature_lags %&gt;%\n  mutate(lag = as.numeric(survey_date - date)) %&gt;%\n  pivot_wider(names_from = lag, values_from = temp_metric, names_prefix = \"temp_lag_\") %&gt;%\n  select(mstudyid, survey_date, starts_with(\"temp_lag_\")) %&gt;%\n  group_by(mstudyid, survey_date) %&gt;%\n  reframe(across(starts_with(\"temp_lag_\"), ~ first(na.omit(.)), .names = \"{col}\")) %&gt;%\n  left_join(crisis_simple %&gt;% select(mstudyid, survey_date, sum_nds_category), by = c(\"mstudyid\", \"survey_date\")) %&gt;%\n  filter(!is.na(temp_lag_0)) # Remove rows without lag 0 data\n\n# create temperature matrix for cross basis\ntemp_data_matrix &lt;- temperature_lags_wide %&gt;%\n  select(starts_with(\"temp_lag_\")) %&gt;%\n  as.matrix()\n\n\n\n# set up DLNM model parameters, fit model, and get predictions\n\n## SET UP PARAMS\n\n# predictor DLNM model parameters -- captures the relationship between the predictor variable (temp) and the outcome\nvar_arg = list(fun = \"bs\", df = 4, degree = 3) # smooth cubic polynomial (degree = 3) between the boundary knots (no internal knots)\n\n# lag DLNM model parameters -- captures the lagged effects of the predictor variable (temp) over time.\nlag_arg = list(fun = \"bs\", df = 4, degree = 3) # smooth cubic polynomial (degree = 3) between the boundary knots (no internal knots)\n\n# cross-basis matrix for DLNM\ncb = crossbasis(temp_data_matrix, lag = c(1, ncol(temp_data_matrix)), argvar = var_arg, arglag = lag_arg) # basis for the predictor and lag \n\n# ordered logistic regression model\nmodel_polr &lt;- polr(\n  formula = sum_nds_category ~ cb,\n  data = temperature_lags_wide,\n  method = \"logistic\" \n)\n\n\n\n# GET PREDICTIONS (in reference to median temp)\ntemp_median &lt;- round(median(as.vector(temp_data_matrix)), 1) # centering value (median). \ncrysis_temp_median &lt;- temp_median\n\n# generate predictions for a DLNM, set centering value as the median of all temperatures\ncpred = crosspred(cb, \n                  model_polr, \n                  ci.level = 0.95, # 95% confidence intervals calculated around predicted values\n                  cen = temp_median, # predictions are relative to this baseline temperature.\n                  by = 0.1) # predictions are generated at intervals of 0.1 units of temperature\n\n\n# plot contour map of 3d plot\nplot(\n  cpred, \n  \"contour\", \n  main = paste0(\"Effects of Temperature and Lag on Log Odds \\nof Higher Stress Category Relative \\nto Median Temperature (\",temp_median, \"°C)\"), \n  xlab = \"Temperature (°C)\", \n  ylab = \"Lag (days)\", \n  key.title = title(main = \"Change in \\nLog Odds\", cex.main = 0.8)\n)\n\n\n\n\n\n\n\n\n\nCode\n# Examine lag effect at top percentile \ntemp_top_pct = round(quantile(as.vector(temp_data_matrix), 0.99), 1) # third quartile of temperature\ntemp_top_pct = as.numeric(temp_top_pct)\ncrysis_temp_top_pct = temp_top_pct\n\n\n## Customized plot of effect at top percentile \nplot_var = temp_top_pct\nplot_var_matfit = cpred$matfit[rownames(cpred$matfit) == plot_var, ]\nnames(plot_var_matfit) = sub(\"lag\", \"\", names(plot_var_matfit))\nplot_var_matlow = cpred$matlow[rownames(cpred$matlow) == plot_var, ]\nnames(plot_var_matlow) = sub(\"lag\", \"\", names(plot_var_matlow))\nplot_var_mathigh = cpred$mathigh[rownames(cpred$mathigh) == plot_var, ]\nnames(plot_var_mathigh) = sub(\"lag\", \"\", names(plot_var_mathigh))\n\nplot(\n  x = names(plot_var_matfit),\n  y = plot_var_matfit,\n  xlab = \"Lag (days)\", \n  ylab = \"Change in Log Odds of Higher Stress Category\",\n  main = paste0(\"Compared to the Median (\", temp_median, \"\\u00B0 C), the Effect of Temperature \\nat the 99th Percentile (\", temp_top_pct,\"\\u00B0 C) is Signficant for Lags 134-247\"),\n  type = \"l\", \n  lwd = 2, \n  ylim = c(min(plot_var_matlow), max(plot_var_mathigh))\n)\n\n# Add shaded confidence intervals\npolygon(\n  x = c(names(plot_var_mathigh), rev(names(plot_var_matlow))),\n  y = c(plot_var_mathigh, rev(plot_var_matlow)),\n  col = rgb(0, 0, 0, alpha = 0.2), \n  border = NA\n)\n\n# Add horizontal line at 0\nabline(h = 0, lty = 2)\n\n\n\n\n\n\n\n\n\nThe plots above illustrate the relationship between temperature and Sum NDS Category over various lag periods. Compared to the median temperature (27.4°C), extreme heat exposure (above 30°C) is associated with higher stress scores, particularly 5–8 months before the survey date."
  },
  {
    "objectID": "posts/2025-01-15-air-quality-monitor/index.html",
    "href": "posts/2025-01-15-air-quality-monitor/index.html",
    "title": "Analyzing Ambient Air Quality Trends in Ghana",
    "section": "",
    "text": "In 2023, our team set up a network of 40 low-cost air pollution monitors across Ghana’s Bono East region—spanning farming communities and the city of Kintampo (population ~111,000), where our Ghanaian research partners are based. While we ran into the typical hurdles that come with rural data collection, such as patchy network connectivity and occasional data gaps, our initial results give us some valuable insights into the area’s air quality.\nThe fleet of monitors recorded an average daily fine particulate matter (PM 2.5) concentration of about 49 μg/m³—a level higher than the World Health Organization’s primary PM 2.5 target of 5 μg/m3 and interim target of 35 μg/m3. We also saw clear daily spikes in pollution during cooking hours (morning and evening) and a large jump in overall pollution during the Harmattan season, a period roughly from late-November to mid-March when a cool dry wind blows dust from the Sahara over much of West Africa.\nElevated levels of particulate matter can significantly influence both maternal health and early childhood development [1][2]. The measurements shared in this report highlight the scale of this issue in Ghana’s rural farming regions and smaller urban centers, informing future epidemiological studies of air pollution risk."
  },
  {
    "objectID": "posts/2025-01-15-air-quality-monitor/index.html#summary",
    "href": "posts/2025-01-15-air-quality-monitor/index.html#summary",
    "title": "Analyzing Ambient Air Quality Trends in Ghana",
    "section": "",
    "text": "In 2023, our team set up a network of 40 low-cost air pollution monitors across Ghana’s Bono East region—spanning farming communities and the city of Kintampo (population ~111,000), where our Ghanaian research partners are based. While we ran into the typical hurdles that come with rural data collection, such as patchy network connectivity and occasional data gaps, our initial results give us some valuable insights into the area’s air quality.\nThe fleet of monitors recorded an average daily fine particulate matter (PM 2.5) concentration of about 49 μg/m³—a level higher than the World Health Organization’s primary PM 2.5 target of 5 μg/m3 and interim target of 35 μg/m3. We also saw clear daily spikes in pollution during cooking hours (morning and evening) and a large jump in overall pollution during the Harmattan season, a period roughly from late-November to mid-March when a cool dry wind blows dust from the Sahara over much of West Africa.\nElevated levels of particulate matter can significantly influence both maternal health and early childhood development [1][2]. The measurements shared in this report highlight the scale of this issue in Ghana’s rural farming regions and smaller urban centers, informing future epidemiological studies of air pollution risk."
  },
  {
    "objectID": "posts/2025-01-15-air-quality-monitor/index.html#monitors",
    "href": "posts/2025-01-15-air-quality-monitor/index.html#monitors",
    "title": "Analyzing Ambient Air Quality Trends in Ghana",
    "section": "Monitors",
    "text": "Monitors\nFor data collection, we used QuantAQ’s ModulairPM and Modulair devices. Before installing them in each community, we colocated the monitors at the Kintampo Health Research Center (KHRC) to cross-check and adjust for any systematic biases between the units. These initial calibrations ensure consistent, high-quality data across all 40 locations. After the colocation period, we deployed the monitors to their respective communities. The maps below illustrates their distribution.\n\n\nCode\n# Define the bounding box coordinates\nbbox_coords &lt;- matrix(c(-2.2, 7.6, -2.2, 8.8, -1.3, 8.8, -1.3, 7.6, -2.2, 7.6), ncol = 2, byrow = TRUE)\nbbox_polygon &lt;- st_polygon(list(bbox_coords))\nbbox_sf &lt;- st_sfc(bbox_polygon, crs = st_crs(4326))\n\n# Plot the map with the bounding box\nghana_full &lt;- ggplot() +\n  # Add Ghana regions\n  geom_sf(data = regions, fill = ifelse(regions$region == \"Bono East\", \"#f5e493\", \"#dadbe0\"), color = \"black\", alpha = 0.5) +\n  # Add monitor points with transparency\n  geom_sf(data = monitor_points, aes(geometry = geometry), color = \"red\", alpha = 0.5, size = 2) +\n  # Add bounding box\n  geom_sf(data = bbox_sf, fill = NA, color = \"blue\", lwd = 0.5, linetype = \"solid\") +\n  # Add Ghana country boundary\n  geom_sf(data = country, fill = NA, color = \"black\", size = 1) +\n  #labs(title = \"Monitor Locations in Ghana\") +\n  theme_bw() +\n  theme(\n    axis.text = element_text(size = 11), # Increase axis text size\n    axis.ticks = element_line(size = 1), # Increase tick mark size\n    plot.title = element_text(size = 16) \n  )\n\n\nzoomed_map &lt;- ggplot() +\n  # Add Ghana regions within the bounding box\n  geom_sf(data = regions, fill = ifelse(regions$region == \"Bono East\", \"#f5e493\", \"#dadbe0\"), color = \"black\", alpha = 0.5) +\n  # Add monitor points with transparency within the bounding box\n  geom_sf(data = monitor_points, aes(geometry = geometry, color = monitor_type), alpha = 0.5, size = 5) +\n  \n  # Add Kintampo marker\n  geom_sf(data = kintampo_sf, aes(geometry = geometry), shape = 20, size = 3, color = \"black\") +\n  # Add Dwenewoho marker\n  geom_sf(data = dwenewoho_sf, aes(geometry = geometry), shape = 20, size = 3, color = \"black\") +\n  # Add new longoro marker\n  geom_sf(data = new_longoro_sf, aes(geometry = geometry), shape = 20, size = 3, color = \"black\") +\n  # Add apesika marker\n  geom_sf(data = apesika_sf, aes(geometry = geometry), shape = 20, size = 3, color = \"black\") +\n  # Add kurawura akura marker\n  geom_sf(data = kurawura_akura_sf, aes(geometry = geometry), shape = 20, size = 3, color = \"black\") +\n  \n  # Add Kintamp annotation text\n  annotate(\"text\", x = -1.73, y = 8.10, label = \"Kintampo\", color = \"black\", size = 5) +\n  # Add Dwenewoho annotation text\n  annotate(\"text\", x = -1.69, y = 7.74, label = \"Dwenewoho\", color = \"black\", size = 5) +\n  # Add new longoro annotation text\n  annotate(\"text\", x = -2.047, y = 8.214, label = \"New Longoro\", color = \"black\", size = 5) +\n  # Add apesika annotation text\n  annotate(\"text\", x = -1.459, y = 7.96, label = \"Apesika\", color = \"black\", size = 5) +\n  # Add atta akura annotation text\n  annotate(\"text\", x = -1.65, y = 8.75, label = \"Kurawura Akura\", color = \"black\", size = 5) +\n  \n  # Zoom in to the bounding box\n  coord_sf(xlim = c(-2.2, -1.3), ylim = c(7.6, 8.8), expand = FALSE) +\n  labs(x = \"\", \n       y = \"\",\n       color = \"Monitor Type\") +\n  theme_bw() +\n  theme(\n    axis.text = element_text(size = 11), # Increase axis text size\n    axis.ticks = element_line(size = 0.5), # Increase tick mark size\n    plot.title = element_text(size = 16), # Increase title size\n    legend.text = element_text(size = 10), # Increase legend text size\n    legend.title = element_text(size = 12) # Increase legend title size\n  )\n\n# Create a joint title\ntitle &lt;- textGrob(\"Monitor Locations in Ghana\", gp = gpar(fontsize = 20))\n\n# Arrange plots with title\ngrid.arrange(\n  arrangeGrob(ghana_full, zoomed_map, ncol = 2),  # Arrange plots\n  top = title  # Add title at the top\n)"
  },
  {
    "objectID": "posts/2025-01-15-air-quality-monitor/index.html#air-quality-index-aqi-context",
    "href": "posts/2025-01-15-air-quality-monitor/index.html#air-quality-index-aqi-context",
    "title": "Analyzing Ambient Air Quality Trends in Ghana",
    "section": "Air Quality Index (AQI) Context",
    "text": "Air Quality Index (AQI) Context\nBefore diving into the results, I wanted to provide some context on air quality measurements. The United States Environmental Protection Agency (U.S. EPA) Air Quality Index (AQI) is a scale that measures pollution levels in the air. The scale is divided into six categories, with each associated with a different color and level of concern. While the final score is calculated using five major air pollutants—particulate matter, ozone, carbon monoxide, sulfur dioxide, and nitrogen dioxide—this analysis will focus on PM 2.5, fine particulate matter with a diameter of 2.5 micrometers or less.\nThe table below shows the EPA’s cutoffs [3] for each health concern category, including both the standard AQI values (the numbers commonly seen in air quality reports and weather apps) and the specific PM 2.5 concentration ranges that contribute to the index.\n\n\n\n\n\n\n\nAQI Category and Index Value\nCorresponding fine particle (PM 2.5) Measurement (µg/m³)\n\n\n\n\nGood (0 – 50)\n0.0 to 9.0\n\n\nModerate (51 – 100)\n9.1 to 35.4\n\n\nUnhealthy for Sensitive Groups (101 – 150)\n35.5 to 55.4\n\n\nUnhealthy (151 – 200)\n55.5 to 125.4\n\n\nVery Unhealthy (201 – 300)\n125.5 to 225.4\n\n\nHazardous (301+)\n225.5+"
  },
  {
    "objectID": "posts/2025-01-15-air-quality-monitor/index.html#results",
    "href": "posts/2025-01-15-air-quality-monitor/index.html#results",
    "title": "Analyzing Ambient Air Quality Trends in Ghana",
    "section": "Results",
    "text": "Results\n\nPM 2.5 Concentrations Over Time\n\n\nCode\n# Define AQI levels with ordered factors\naqi_levels &lt;- data.frame(\n  ymin = c(0, 9.1, 35.5, 55.5, 125.5, 225.5),\n  ymax = c(9, 35.4, 55.4, 125.4, 225.4, 450),\n  fill = factor(c(\"Good\", \"Moderate\", \"Unhealthy for Sensitive Groups\", \n                  \"Unhealthy\", \"Very Unhealthy\", \"Hazardous\"), \n                levels = c(\"Good\", \"Moderate\", \"Unhealthy for Sensitive Groups\", \n                           \"Unhealthy\", \"Very Unhealthy\", \"Hazardous\")),\n  color = c(\"green\", \"yellow\", \"orange\", \"red\", \"purple\", \"maroon\")\n)\n\n# Plot with legend inside the graph\ndaily_pollutants_long %&gt;%\n  filter(pollutant == \"Mean PM 2.5\") %&gt;% \n  ggplot(aes(x = date, y = measurement)) +\n  # Add background rectangles for AQI levels\n  geom_rect(data = aqi_levels, \n            aes(xmin = min(daily_pollutants_long$date), \n                xmax = max(daily_pollutants_long$date), \n                ymin = ymin, \n                ymax = ymax, \n                fill = fill), \n            color = NA, alpha = 0.2, inherit.aes = FALSE) +\n  # Add the PM 2.5 line\n  geom_line(color = \"black\") +\n  theme_bw() +\n  labs(title = \"Daily Mean PM 2.5 Suggests Levels of Concern for Sensitive Groups Year Round \\nwith Unhealthy Air Quality for All During the Harmattan.\",\n       x = \"Date\",\n       y = bquote(\"Fleet Mean \" ~ PM[2.5] ~ (µg/m^3)),\n       fill = \"US-EPA AQI Risk Categories\") +  # Add legend title for the AQI levels\n  theme(\n    plot.title = element_text(size=20), # set title size \n    axis.title = element_text(size = 16),   # Increase axis titles size\n    axis.text = element_text(size = 14),    # Increase axis labels size\n    strip.text = element_text(size = 14),    # Increase facet group text size\n    legend.position = c(0.77, 0.73),  # Position legend inside the graph (top right)\n    legend.background = element_rect(fill = rgb(1, 1, 1, alpha = 0.7), color = \"black\"),\n    legend.title = element_text(size = 14),  # Adjust legend title size\n    legend.text = element_text(size = 12)    # Adjust legend text size\n  ) +\n  scale_fill_manual(values = aqi_levels$color) +\n  guides(fill = guide_legend(reverse = TRUE))  # Reverse the order of the legend\n\n\n\n\n\n\n\n\n\nThe figure above shows that PM 2.5 levels often exceed the ‘good’ to ‘moderate’ AQI range, particularly from December through February—roughly the Harmattan season.\nWe see similar trends for other sizes of particulate matter, as illustrated in the three-panel plot below. The first panel highlights PM1 concentrations (mean 37 µg/m³), the second panel shows PM 2.5 (mean 43.2 µg/m³), and the third panel displays PM10 (mean 101 µg/m³). All three exhibit noticeable peaks during the dry, dusty Harmattan months, suggesting that the same sources (such as windblown dust) drive increases across all particle sizes.\n\n\nCode\ndaily_pollutants_long %&gt;%\n  ggplot(aes(x = date, y = measurement)) +\n  geom_line() +\n  geom_hline(aes(yintercept = mean_measurement), color = \"#cc1414\", linetype = \"dashed\") +\n  geom_text(data = mean_values, aes(x = max(daily_pollutants_long$date), y = mean_measurement, label = paste0(pollutant, \": \", round(mean_measurement, 2), \" µg/m³\")),\n            color = \"#cc1414\", hjust = 1, vjust = -0.9, size = 4.5) +\n  theme_bw() +\n  labs(title = \"Grand Averages Patterns Consistent Across Particle Sizes\",\n       x = \"Date\",\n       y = \"Pollutant Measurement (µg/m³)\") +\n  facet_grid(factor(pollutant, levels = c(\"Mean PM 1\", \"Mean PM 2.5\", \"Mean PM 10\" )) ~ ., scales = \"free_y\") +\n  theme(\n    plot.title = element_text(size = 20),\n    axis.title = element_text(size = 16),   # Increase axis titles size\n    axis.text = element_text(size = 14),    # Increase axis labels size\n    strip.text = element_text(size = 14)  # Increase facet group text size\n  )\n\n\n\n\n\n\n\n\n\n\n\nHourly PM 2.5 Results\n\n\nCode\npm25_community_hourly &lt;- pm25_community_hourly %&gt;%\n    mutate(date = ymd(date))  # Use lubridate to ensure date conversion\n  \nheat_map_data &lt;- pm25_community_hourly %&gt;%\n    group_by(date, hour) %&gt;%\n    summarize(mean_pm25 = mean(mean_pm25, na.rm = TRUE), .groups = 'drop') %&gt;%\n    ungroup() %&gt;%\n    mutate(day = day(date),\n           month = factor(format(date, \"%b\"), levels = c(\"Sep\", \"Oct\", \"Nov\", \"Dec\", \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\")),\n           year = year(date)) %&gt;%\n  mutate(log_mean_pm25 = log(mean_pm25))\n\n\nggplot(heat_map_data, aes(day, hour, fill = mean_pm25)) +\n    geom_tile(color = NA, size = 0) + \n    scale_fill_gradientn(\n        colors = c(\"#221f26\", \"#3f2363\", \"#872CA2\", \"#D44292\", \"#F98477\", \"#EDD9A1\", \"#fffceb\"), # Specify your custom colors\n        values = scales::rescale(c(0, 5, 12, 20, 40, 60, 100)), # Set breaks; adjust these values based on your data range\n        name = \"PM 2.5 \\n(µg/m³)\"\n    ) + \n    facet_grid(~month) +\n    scale_y_continuous(trans = \"reverse\", breaks = unique(heat_map_data$hour)) +\n    scale_x_continuous(breaks = c(1, 15, 30)) +\n    theme_minimal(base_size = 8) +\n    labs(title = \"Heatmap Shows Strong Seasonal and Daily Patterns in PM 2.5\",\n         x = \"Day\",\n         y = \"Hour\") + \n    theme(legend.position = \"right\",\n          plot.title = element_text(size = 20, hjust = 0),\n          axis.text.y = element_text(size = 12),\n          strip.background = element_rect(colour = \"white\"),\n          strip.text = element_text(size = 15),   # Increase facet group text size\n          axis.ticks = element_blank(),\n          axis.text = element_text(size = 9),\n          legend.title = element_text(size = 14),\n          legend.text = element_text(size = 13),\n          axis.title.y = element_text(size = 16),\n          axis.title.x = element_text(size = 16),\n          panel.background = element_blank())\n\n\n\n\n\n\n\n\n\nThe heatmap illustrates how both season and time of day affect PM 2.5 concentrations across all 40 monitors. During the Harmattan season (December–February), PM 2.5 levels stay elevated, peaking in the early morning (6–8 a.m.) and early evening (5–9 p.m.). These spikes likely coincide with cooking and other daily activities that generate or stir up particulate matter. As the Harmattan subsides around March, average PM levels drop, and remain lower into the late spring and early summer months.\n\n\nCode\nbase_plot &lt;- pm25_community_hourly %&gt;% \n  mutate(harmattan = ifelse(date &gt;= harmattan_start & date &lt;= harmattan_end, \"Harmattan\", \"Not Harmattan\")) %&gt;%\n  mutate(\n    cooking_period = factor(case_when(\n      hour &gt;= 16 & hour &lt;= 19 ~ \"Evening Cooking Hours\", #4-9pm\n      hour &gt;= 5 & hour &lt;= 8 ~ \"Morning Cooking Hours\", #5-9am\n      (hour &lt; 16 | hour &gt; 19) &  (hour &lt; 5 | hour &gt; 8) & hour != 3 ~ \"Other Hours\",\n      hour == 3 ~ \"Control Hour\"\n    ), levels = c(\"Evening Cooking Hours\", \"Morning Cooking Hours\", \"Control Hour\", \"Other Hours\"))\n  ) %&gt;%\n  filter(!is.na(hour)) %&gt;%\n  ggplot(aes(x = harmattan, y = mean_pm25, fill = cooking_period)) +\n  geom_boxplot() +\n  theme_classic() +\n  labs(y = \"PM 2.5 Concentration\", \n       x = \"Season\",\n       fill = \"Cooking\\nPeriod\") +  # Change legend title and add line breaks\n  theme(legend.position = \"right\") +\n  scale_fill_manual(values = c(\n    \"Evening Cooking Hours\" = \"goldenrod\", \n    \"Morning Cooking Hours\" = \"#7db569\", \n    \"Control Hour\" = \"#b672e0\",\n    \"Other Hours\" = \"#52b3eb\"\n  ),\n  labels = c(\"Evening Cooking Hours (4pm-8pm)\", \"Morning Cooking Hours (5am-9am)\", \"Control Hour (3am)\", \"Other Hours (Excluding Cooking \\nand Control Hours)\"))  # Add line breaks in legend labels\n\n\nbase_plot +\n  geom_segment(aes(x = 0.72, xend = 0.90, y = 515, yend = 515), color = \"black\") +  # Harmattan \n  annotate(\"text\", x = 0.81, y = 518, label = \"***\") +\n  \n  geom_segment(aes(x = 0.91, xend = 1.09, y = 515, yend = 515), color = \"black\") +  # Harmattan \n  annotate(\"text\", x = 1, y = 518, label = \"***\") +\n  \n  geom_segment(aes(x = 1.10, xend = 1.28, y = 515, yend = 515), color = \"black\") +  # Harmattan \n  annotate(\"text\", x = 1.19, y = 518, label = \"**\") +\n  \n  geom_segment(aes(x = 0.72, xend = 1.09, y = 525, yend = 525), color = \"black\") +  # Harmattan \n  annotate(\"text\", x = 0.9, y = 529, label = \"***\") +\n  \n  geom_segment(aes(x = 0.91, xend = 1.27, y = 536, yend = 536), color = \"black\") +  # Harmattan\n  annotate(\"text\", x = 1.09, y = 540, label = \"***\") +\n  \n  geom_segment(aes(x = 0.72, xend = 1.27, y = 548, yend = 548), color = \"black\") +  # Harmattan\n  annotate(\"text\", x = 1, y = 552, label = \"***\") +\n  \n  \n  \n  geom_segment(aes(x = 1.72, xend = 1.90, y = 360, yend = 360), color = \"black\") +  # Not Harmattan \n  annotate(\"text\", x = 1.81, y = 364, label = \"***\") +\n  \n  geom_segment(aes(x = 1.91, xend = 2.09, y = 360, yend = 360), color = \"black\") +  # Not Harmattan \n  annotate(\"text\", x = 2.0, y = 364, label = \"***\") +\n  \n  geom_segment(aes(x = 2.10, xend = 2.28, y = 360, yend = 360), color = \"black\") +  # Not Harmattan \n  annotate(\"text\", x = 2.19, y = 364, label = \"***\") +\n  \n  geom_segment(aes(x = 1.72, xend = 2.09, y = 372, yend = 372), color = \"black\") +  # Not Harmattan \n  annotate(\"text\", x = 1.9, y = 376, label = \"***\") +\n  \n  geom_segment(aes(x = 1.91, xend = 2.28, y = 384, yend = 384), color = \"black\") +  # Not Harmattan \n  annotate(\"text\", x = 2.09, y = 388, label = \"***\") +\n  \n  geom_segment(aes(x = 1.72, xend = 2.27, y = 396, yend = 396), color = \"black\") +  # Not Harmattan \n  annotate(\"text\", x = 2, y = 400, label = \"***\") +\n  \n  \n  geom_segment(aes(x = 1, xend = 2, y = 590, yend = 590), color = \"black\") +  # Harmattan vs Not Harmattan\n  annotate(\"text\", x = 1.5, y = 600, label = \"***\") +\n  \n  labs(title = \"Higher Ambient PM 2.5 Concentrations During Cooking Periods Persist Across Season\",\n    caption =\"Comparisons and their significance are denoted by the horizontal lines: \\n* indicates p &lt;0.05, ** indicates p &lt; 0.01, and *** indicates p &lt; 0.001\") +\n  \n  theme(\n    plot.title = element_text(size = 20),\n    axis.text = element_text(size = 13), # Increase axis text size\n    axis.ticks = element_line(size = 0.7), # Increase tick mark size\n    legend.text = element_text(size = 12), # Increase legend text size\n    legend.title = element_text(size = 14), # Increase legend title size\n    plot.caption = element_text(size = 13),\n    axis.title.x = element_text(size = 15),\n    axis.title.y = element_text(size = 15),\n  )\n\n\n\n\n\n\n\n\n\nThe boxplots above further examine the relationship between seasonal Harmattan, peak cooking times, and air pollution. For this analysis, Harmattan was defined from December 1st to March 1st, morning cooking hours between 5–9am, and evening cooking hours between 4–8pm, based on our research partners’ local knowledge of the region. As a comparison to the cooking hours, I looked at a control hour (3am) in the middle of the night as it should be completely unaffected by human behavior, as well as a group of ‘other hours’ that excluded the cooking hours and the control hour, leaving me with a total of 4 groups.\nI utilized ANOVAs to test for differences in the time groupings for the entire data, and then for each season separately. The results were highly significant for each test, so I moved forward with Tukey’s HSD to further examine the differences in means for each group. Partially due to the large number of observations in the data (and thus small standard deviations), all differences between groups were highly significant.\nRegarding seasonality, as expected, PM 2.5 concentration was higher (M = 84, SD = 60) on average during Harmattan months than non-Harmattan months (M = 26, SD = 24). During the Harmattan, evening cooking hours (M = 131, SD = 77) were associated with the highest pollution levels, followed by morning cooking hours (M = 95, SD = 64), with other hours (M = 74, SD = 48) and the control hour (M = 70, SD = 45) experiencing lower levels. The same order held outside of Harmattan, with evening cooking hours (M = 47, SD = 34) associated with the highest PM 2.5 concentration, then morning cooking hours (M = 25, SD = 19), then other hours (M = 21, SD = 19), and finally the control hour (M = 16, SD = 13).\n\n\nSpatial Variability\n\n\nCode\n# DURING HARMATTAN ----\n\n#PM 2.5\npm25_summary_harmattan &lt;- pm25_corrected %&gt;%\n  filter(date &gt;= harmattan_start & date &lt; harmattan_end) %&gt;%\n  group_by(monitor) %&gt;%\n  summarise(mean_pm25 = mean(pm25, na.rm = TRUE),\n            median_pm25 = median(pm25, na.rm = TRUE)) %&gt;%\n  right_join(monitor_points)\n\n\nharmattan_spatial_plot &lt;- ggplot() +\n  # Add Ghana regions within the bounding box\n  geom_sf(data = regions, fill = ifelse(regions$region == \"Bono East\", \"#f5e493\", \"#dadbe0\"), color = \"black\", alpha = 0.5)  +\n  \n  # Add road data\n  geom_sf(data = roads_filtered, color = \"gray\", size = 0.3) +  # Add roads data\n  \n  # Add monitor points with transparency within the bounding box\n  geom_sf(data = pm25_summary_harmattan, aes(geometry = geometry, color = mean_pm25), alpha = 0.7, size = 6) +\n\n  # Zoom in to the bounding box\n  coord_sf(xlim = c(-2.2, -1.3), ylim = c(7.6, 8.8), expand = FALSE) +\n  \n  # Customize\n  labs(title = \"Mean PM 2.5 for Each Monitor During Harmattan\",\n       x = \"\", \n       y = \"\") +\n  theme_bw() +\n  scale_color_gradient(low = \"#0540a1\", high = \"#eb4c2d\",\n                       breaks = c(min(pm25_summary_harmattan$mean_pm25), 85, 110, max(pm25_summary_harmattan$mean_pm25)),\n                       labels = c(paste(round(min(pm25_summary_harmattan$mean_pm25),0)), \"85\", \"110\", paste(round(max(pm25_summary_harmattan$mean_pm25),0))),\n                       name = \"PM 2.5 \\n(µg/m³)\") +\n  theme(\n    axis.text = element_text(size = 11), # Increase axis text size\n    axis.ticks = element_line(size = 0.7), # Increase tick mark size\n    plot.title = element_text(size = 14), # Increase plot title size\n    legend.text = element_text(size = 12), # Increase legend text size\n    legend.title = element_text(size = 12), # Increase legend title size\n    legend.key.size = unit(1.3, \"lines\") # Increase legend tick mark size\n  )\n\n\n# OUTSIDE OF HARMATTAN ----\n\npm25_summary_not_harmattan &lt;- pm25_corrected %&gt;%\n  filter(date &lt; harmattan_start | date &gt;= harmattan_end) %&gt;%\n  group_by(monitor) %&gt;%\n  summarise(mean_pm25 = mean(pm25, na.rm = TRUE),\n            median_pm25 = median(pm25, na.rm = TRUE)) %&gt;%\n  right_join(monitor_points)\n\nnot_harmattan_spatial_plot &lt;- ggplot() +\n  # Add Ghana regions within the bounding box\n  geom_sf(data = regions, fill = ifelse(regions$region == \"Bono East\", \"#f5e493\", \"#dadbe0\"), color = \"black\", alpha = 0.5)  +\n  \n  # Add road data\n  geom_sf(data = roads_filtered, color = \"gray\", size = 0.3) +  # Add roads data\n  \n  # Add monitor points with transparency within the bounding box\n  geom_sf(data = pm25_summary_not_harmattan, aes(geometry = geometry, color = mean_pm25), alpha = 0.7, size = 6) +\n\n  # Zoom in to the bounding box\n  coord_sf(xlim = c(-2.2, -1.3), ylim = c(7.6, 8.8), expand = FALSE) +\n  \n  # Customize\n  labs(title = \"Mean PM 2.5 for Each Monitor Outside of Harmattan\",\n       x = \"\", \n       y = \"\") +\n  theme_bw() +\n  scale_color_gradient2(low = \"#0540a1\", mid = \"#eb4c2d\", high = \"goldenrod\", \n                        midpoint = 55,  # Set the midpoint value\n                        breaks = c(min(pm25_summary_not_harmattan$mean_pm25, na.rm = TRUE),35, 55, max(pm25_summary_not_harmattan$mean_pm25)),\n                        labels = c(paste(round(min(pm25_summary_not_harmattan$mean_pm25),0)),\"35\", \"55\", paste(round(max(pm25_summary_not_harmattan$mean_pm25),0))),\n                        name = \"PM 2.5 \\n(µg/m³)\") +\n  theme(\n    axis.text = element_text(size = 11), # Increase axis text size\n    axis.ticks = element_line(size = 0.7), # Increase tick mark size\n    plot.title = element_text(size = 14), # Increase plot title size\n    legend.text = element_text(size = 12), # Increase legend text size\n    legend.title = element_text(size = 12), # Increase legend title size\n    legend.key.size = unit(1.3, \"lines\") # Increase legend tick mark size\n  )\n\n# Create a joint title\ntitle &lt;- textGrob(\"Maps of Pollution Levels for PM 2.5 Show Spatial Variability in the Monitors.\", gp = gpar(fontsize = 20))\n\n# Arrange plots with title\ngrid.arrange(\n  arrangeGrob(harmattan_spatial_plot, not_harmattan_spatial_plot, ncol = 2),  # Arrange plots\n  top = title  # Add title at the top\n)\n\n\n\n\n\n\n\n\n\nThe maps above display the mean PM 2.5 levels for each monitor in the study area. The plots show that PM concentrations vary across the region, with certain monitors recording higher mean pollutant levels. These spatial patterns suggest that local environmental factors and/or human activities may influence pollution levels, leading to the observed variations in PM concentrations.\nWhile there is variation in pollution levels across the communities, I used Moran’s I test to look for spatial correlation and found no evidence that the variation can be explained by the location alone. I also tried running regressions to see if proximity to road, type of road, and population of the community could explain the variation, but found no evidence of an association with any of these predictors."
  },
  {
    "objectID": "posts/2025-01-15-air-quality-monitor/index.html#conclusions",
    "href": "posts/2025-01-15-air-quality-monitor/index.html#conclusions",
    "title": "Analyzing Ambient Air Quality Trends in Ghana",
    "section": "Conclusions",
    "text": "Conclusions\nThese results underscore the significant day-to-day and seasonal fluctuations in air quality across Ghana’s Bono East region, particularly during the Harmattan months and around cooking hours. They point to an urgent need for both seasonal and local interventions—whether through cleaner fuels, improved ventilation, or other strategies—to reduce PM 2.5 exposure.\nBuilding on these insights, my ongoing research at Columbia focuses on supporting communities as they transition from charcoal to cleaner-burning LPG, which holds promise for substantially lowering pollution and improving maternal and child health outcomes. This evidence strengthens the case for adopting cleaner cooking practices and highlights the value of continued monitoring to guide effective, data-driven solutions."
  },
  {
    "objectID": "posts/2025-01-15-air-quality-monitor/index.html#references",
    "href": "posts/2025-01-15-air-quality-monitor/index.html#references",
    "title": "Analyzing Ambient Air Quality Trends in Ghana",
    "section": "References",
    "text": "References\n[1]: Quinn, A. K., Adjei, I. A., Ae-Ngibise, K. A., Agyei, O., Boamah-Kaali, E. A., Burkart, K., Carrión, D., Chillrud, S. N., Gould, C. F., Gyaase, S., Jack, D. W., Kaali, S., Kinney, P. L., Lee, A. G., Mujtaba, M. N., Oppong, F. B., Owusu-Agyei, S., Yawson, A., Wylie, B. J., & Asante, K. P. (2021). Prenatal household air pollutant exposure is associated with reduced size and gestational age at birth among a cohort of Ghanaian infants. Environment International, 155, 106659.https://doi.org/10.1016/j.envint.2021.106659\n[2]: Lacasaña, M., Esplugues, A., & Ballester, F. (2005). Exposure to ambient air pollution and prenatal and early childhood health effects. European Journal of Epidemiology, 20(2), 183–199.https://doi.org/10.1007/s10654-004-3005-9\n[3] EPA. Final Updates to the Air Quality Index (AQI) for Particulate Matter Fact Sheet and Common Questions - Policy Brief. Available from: https://www.epa.gov/system/files/documents/2024-02/pm-naaqs-air-quality-index-fact-sheet.pdfttps://www.epa.gov/system/files/documents/2024-02/pm-naaqs-air-quality-index-fact-sheet.pdf"
  },
  {
    "objectID": "posts/2022-12-03-asthma-blog/index.html",
    "href": "posts/2022-12-03-asthma-blog/index.html",
    "title": "Modeling Asthma Hospitalizations",
    "section": "",
    "text": "Asthma is a chronic disease that affects the respiratory system. During an asthma attack, an individual’s airways constrict and swell, causing a combination of coughing, wheezing, shortness of breath, and chest tightness [1]. For some individuals, symptoms can be quite mild and handled easily with preventative medication. For others, asthma can be a life threatening disease that severely reduces their quality of life. \nGlobally, asthma affected roughly 262 million people and caused over 450,000 deaths in 2019 [2]. While not quite as severe in the United States, it’s estimated that 25 million Americans have asthma and over 4,000 die from asthma each year. It is important to note that asthma does not affect all groups equally: statistics provided by the CDC demonstrate that asthma is more common among women, individuals living in poverty, and Black and indigenous people [3]. \nAs someone with asthma, I’m generally pretty cognizant of things that trigger my asthma flare ups. For example, I’ve noticed that I am particularly sensitive to poor air quality. In 2020, I was living in Minnesota during a particularly severe period of Canadian wildfires—the smoke from these fires affected both the air quality and my severity of asthma. During this time, I frequently looked at a variety of weather apps to check the air quality before doing any activity that required me to be outside for an extended period of time. \nIt’s fairly intuitive that air quality would have an impact on asthma, an upper respiratory disease, and this idea is supported by research [4]. However, it is not as clear just how strong this impact is, as well as what other factors are at play in determining asthma attack prevalence. In this study, I will explore how a variety of factors affect the rate of hospitalizations caused by asthma for each county in California. I will also test a hypothesis that there are more asthma related hospitalizations in years when more acres of land burned due to wildfire. As drought continues in California and wildfires seem likely to worsen, it’s prudent that we examine how air quality and wildfire smoke impact asthma."
  },
  {
    "objectID": "posts/2022-12-03-asthma-blog/index.html#introduction",
    "href": "posts/2022-12-03-asthma-blog/index.html#introduction",
    "title": "Modeling Asthma Hospitalizations",
    "section": "",
    "text": "Asthma is a chronic disease that affects the respiratory system. During an asthma attack, an individual’s airways constrict and swell, causing a combination of coughing, wheezing, shortness of breath, and chest tightness [1]. For some individuals, symptoms can be quite mild and handled easily with preventative medication. For others, asthma can be a life threatening disease that severely reduces their quality of life. \nGlobally, asthma affected roughly 262 million people and caused over 450,000 deaths in 2019 [2]. While not quite as severe in the United States, it’s estimated that 25 million Americans have asthma and over 4,000 die from asthma each year. It is important to note that asthma does not affect all groups equally: statistics provided by the CDC demonstrate that asthma is more common among women, individuals living in poverty, and Black and indigenous people [3]. \nAs someone with asthma, I’m generally pretty cognizant of things that trigger my asthma flare ups. For example, I’ve noticed that I am particularly sensitive to poor air quality. In 2020, I was living in Minnesota during a particularly severe period of Canadian wildfires—the smoke from these fires affected both the air quality and my severity of asthma. During this time, I frequently looked at a variety of weather apps to check the air quality before doing any activity that required me to be outside for an extended period of time. \nIt’s fairly intuitive that air quality would have an impact on asthma, an upper respiratory disease, and this idea is supported by research [4]. However, it is not as clear just how strong this impact is, as well as what other factors are at play in determining asthma attack prevalence. In this study, I will explore how a variety of factors affect the rate of hospitalizations caused by asthma for each county in California. I will also test a hypothesis that there are more asthma related hospitalizations in years when more acres of land burned due to wildfire. As drought continues in California and wildfires seem likely to worsen, it’s prudent that we examine how air quality and wildfire smoke impact asthma."
  },
  {
    "objectID": "posts/2022-12-03-asthma-blog/index.html#data",
    "href": "posts/2022-12-03-asthma-blog/index.html#data",
    "title": "Modeling Asthma Hospitalizations",
    "section": "Data",
    "text": "Data\nIn order to answer the above questions, I obtained data from a variety of sources.\n\nCounty level Air Quality Index (AQI) data was retrieved from the EPA [5].\nBi-yearly asthma prevalence [6] and yearly hospitalization counts [7] were obtained from the California Health and Human Services (CHHS) Open Data Portal .\nA shapefile containing county level geographic information was obtained from the California Open Data Portal [8]. \nSmoke data, measured in daily PM 2.5 estimates, was retrieved from the Environmental Change and Human Outcomes (ECHO) lab at Stanford [9]. \nCounty level demographic information was collected by the United States Census Bureau [10]."
  },
  {
    "objectID": "posts/2022-12-03-asthma-blog/index.html#methods",
    "href": "posts/2022-12-03-asthma-blog/index.html#methods",
    "title": "Modeling Asthma Hospitalizations",
    "section": "Methods",
    "text": "Methods\nOnce I read in each of the datasets, I cleaned them to follow the ‘Tidy Data’ format, selected desired columns and rows, and joined the datasets [11]. New columns, such as the mean smoke (measured in PM 2.5) per year for each county were created. High levels of PM 2.5, fine particles typically smaller than 2.5 µm in diameter, are a great concern to public health because PM 2.5 can travel deeper into the lungs than larger particulate matter. I also adjusted the maximum AQI values to not exceed 500—the EPA’s highest level of healthy concern, “Hazardous,” ranges from index values of 301–500 so any value above that is functionally equivalent. \nAll analyses, specifically an Ordinary Linear Regression (OLS) model and a Welch t-test (α &lt; 0.05) were conducted in Rstudio.\nFor the outcome variable in the regression, I wanted to focus on hospitalizations due to asthma. Hospitalizations, used as a proxy for measuring the severity of asthma attacks, seem particularly sensitive to climate related triggers that could vary over the years for which my data was collected. Since hospitalizations per county vary significantly with the population of the county, I normalized the variable by calculating the hospitalization rate per 100,000 people. \nBefore jumping into modeling, each variable of interest was examined to ensure that it adhered to the assumptions required for OLS. The max AQI and population density explanatory variables were log transformed to normalize outliers and linearize the distribution, and I took the square root of the mean smoke variable for a similar effect. For each of these variables, there was still some minor heteroskedasticity shown in residual plots. There were also more extreme positive residuals than negative residuals; however, the relationships all appeared mostly linear and histograms of the residuals were fairly normal, so I concluded that proceeding with caution would be acceptable. \nFor the Welch t-test, I wanted to examine whether there is a difference in the hospitalization rate during more severe wildfire years. To do this, I compared the mean hospitalization rate in 2016 (669,534 acres burnt due to wildfire) and 2018 (1,975,086 acres burnt due to wildfire)."
  },
  {
    "objectID": "posts/2022-12-03-asthma-blog/index.html#results-discussion",
    "href": "posts/2022-12-03-asthma-blog/index.html#results-discussion",
    "title": "Modeling Asthma Hospitalizations",
    "section": "Results + Discussion",
    "text": "Results + Discussion\nTo determine the magnitude and significance at which various explanatory variables relate to hospitalizations, I conducted an OLS multiple regression. \nFor model selection, I utilized two different approaches. First, I completed the model selection manually by choosing variables/interactions that I thought could be meaningful and then eventually removing ones that were insignificant and didn’t have as strong of a theoretical rationale for why they should be included in the model. Then, I included a backward stepwise model selection process by using the `stepAIC()` function in the MASS package—this allowed me to automate the process of selecting which variables should be included to optimize the model. With backwards steps, we start the stepwise process with all predictors and remove the least statistically significant one until we find the model with the lowest AIC (a measure of goodness of fit) value [12]. Both approaches led me to the same predictor variables of interest: log(max AQI), sqrt(mean PM from smoke), log(population density), and median income. \n\n\nCode\n#CREATING A MAP OF THE HOSPITALIZATION RATE\nhosp_ggplot &lt;- ggplot() +\n  geom_sf(data = hosp_year_summaries, \n          aes(fill = mean_hosp), col = 'black', size = 0.5) +  #fill color is the mean hospitalization rate from asthma, borders are black\n  labs(title = \"Hospitalization Rate from Asthma between \\n 2015–2019 for California Counties\") +\n  theme_bw() +\n  theme(axis.title.x = element_blank(), #creating a blank background\n        axis.title.y = element_blank(),\n        axis.ticks.x = element_blank(),\n        axis.ticks.y = element_blank(),\n        panel.grid = element_blank(),\n        panel.border = element_blank(),\n        axis.text = element_blank(),\n        legend.direction = \"vertical\",  #specifying legend characteristics\n        legend.position = c(1, 0.75),\n        legend.key.height = unit(0.3, \"cm\"),\n        legend.key.width = unit(0.3, \"cm\")) +\n  scale_fill_stepsn(colors = c(\"#fff0d6\",  #specifying the color scheme \n                               \"#ffffb2\", \n                               \"#fecc5c\", \n                               \"#fd8d3c\", \n                               \"#f03b20\", \n                               \"#bd0026\"),\n                    na.value = \"grey50\",\n                    guide = guide_colorbar(title = \"Hospitalization Rate \\n (per 100,000)\")) #specifying the legend title \n\n\n#I then create 4 more plots for each of my explanatory variables. To see this code, checkout my full repository. \n\n\n#SAVING THE IMAGE AND READING IT BACK INTO R\nggsave(filename = \"hosp_map.png\", plot=hosp_ggplot, \n       width=6, height=4, units = \"in\") #save the plot as a png\n\nhosp_map_png &lt;- image_read(\"hosp_map.png\")  #read the png into R\n\n\n\n#MAKING THE ANIMATION\ngif_images &lt;- c(hosp_map_png, income_map_png, density_map_png, aqi_map_png, smoke_map_png)  #Creating a vector of images\n\nasthma_animation &lt;- image_animate(image_scale(gif_images, \"400x400\"), fps = 0.5, dispose = \"previous\") #creating the animation\n\nimage_write(asthma_animation, \"asthma_vars.gif\") \n#if you want to save your gif to your computer, image_write() allows you to do so!\n\nasthma_animation\n\n\n\n\n\n\n\n\n\nThrough spatial visualization of the data, we can get an initial sense of how a couple of the model’s explanatory variables correlate with the county level hospitalization rate. Southern California and the Central Valley appear to have higher mean AQI values and a higher hospitalization rate. Fine particulate matter from wildfires, meanwhile, appears to have an opposite effect with higher values in Northern California as well as the northern section of the Central Valley. Looking at the population density and median income maps, it is harder to see how they correlate with the hospitalization rate. Below, we examine how each predictor relates to the hospitalization rate in more detail.\n\n\nCode\nasthma_mod &lt;- lm(hosp_per_100k ~ log(max_aqi) + sqrt(mean_smokePM) + log(pop_density_sq_m) + median_income_in_thousands, data = hosp_full)\n\nasthma_hosp_table &lt;- tab_model(asthma_mod,\n                               pred.labels = c(\"Intercept\", \n                                               \"Log Max AQI\", \n                                               \"SQRT Mean Smoke\", \n                                               \"Log Pop Density\", \n                                               \"Median Income (in $1000s)\"),\n                               dv.labels = c(\"Hospitalization Rate (per 100k)\"),\n                               string.ci = \"Conf. Int (95%)\",\n                               string.p = \"P-value\",\n                               title = \"Table 1. Linear Model Results\",\n                               digits = 3)\n\nasthma_hosp_table\n\n\n\n\nTable 1. Linear Model Results\n\n\n \nHospitalization Rate (per 100k)\n\n\nPredictors\nEstimates\nConf. Int (95%)\nP-value\n\n\nIntercept\n0.362\n-23.806 – 24.530\n0.976\n\n\nLog Max AQI\n11.037\n6.467 – 15.608\n&lt;0.001\n\n\nSQRT Mean Smoke\n-3.422\n-5.544 – -1.300\n0.002\n\n\nLog Pop Density\n4.293\n2.839 – 5.747\n&lt;0.001\n\n\nMedian Income (in $1000s)\n-0.408\n-0.535 – -0.281\n&lt;0.001\n\n\nObservations\n249\n\n\nR2 / R2 adjusted\n0.250 / 0.238\n\n\n\n\n\n\n\n\nResults from the model indicate that air quality (measured through AQI and particulate matter from smoke), population density, and median income are all statistically significant predictors of the hospitalization rate. \nBefore diving into each predictor variable, it’s important to emphasize the difference between AQI measurements and PM 2.5. The AQI is typically calculated using hourly measurements of 5 pollutants: fine particles (PM 2.5 and PM 10), ground-level ozone, sulfur dioxide, nitrogen dioxide, and carbon monoxide. This means that smoke from wildfires, measured in PM 2.5, is one of the factors that impacts the AQI. By including smoke from wildfires as a separate variable, I am able to examine that separately. \nStarting with the air quality index, there is a positive trend between the log of the maximum AQI and the hospitalization rate (\\(p &lt; 0.001\\), \\(\\beta = 11.037\\)) . Intuitively, this makes sense, as it seems more likely that severe asthma flare-ups could result from dangerous air quality values. \nPrevious studies have indicated that particular matter from wildfires can actually be more harmful for individuals with asthma than from other sources, so it was surprising that the square root of the PM 2.5 caused by wildfire smoke was negatively associated with the hospitalizations (\\(p = 0.002\\), \\(\\beta = -3.422\\)) [13]. One possible explanation for this result is that individuals with asthma were much less likely to go outside during times when wildfire smoke was particularly severe. Compared to the other measures of air quality, wildfire smoke is much more noticeable, so individuals with asthma who have the ability to avoid interacting with the smoke would likely choose to do so. \nThere was a positive trend between the log of the population density per square mile and the county level hospitalization rate (\\(p &lt; 0.001\\), \\(\\beta = 4.293\\)). It makes sense that asthma may be worse in urban areas due to increased pollution, but this \\(\\beta\\) value is the slope for the population density while holding the other variables constant. It’s possible that there are other factors, such as different forms of pollution, increased proximity to hospitals, or other demographic information that could be influencing the effect of population density. Median income, unsurprisingly, had a negative relationship with the hospitalization rate (\\(p &lt; 0.001\\), \\(\\beta = -0.408\\)). Higher income individuals are more likely to be able to afford asthma prevention and likely have access to cleaner indoor air. \nOverall, the model’s predictive power is not too strong. With an \\(R^2\\) of 0.250, just 25% of variability in the per county hospitalization rate can be explained using the explanatory variables. To further test the model’s predictive power, I used it to predict hospitalization rates for my existing data and then compared the predictions to the true observed hospitalization rates in the graph below. The graph demonstrates that the predictions trend in the right direction but vary a fair amount in their accuracy, especially for observations when the true hospitalization rate was above 60 people per 100,000.\n\n\nCode\nasthma_mod &lt;- lm(hosp_per_100k ~ log(max_aqi) + sqrt(mean_smokePM) + log(pop_density_sq_m) + median_income_in_thousands, data = hosp_full) #the final model\n\npredictions &lt;- augment(asthma_mod) #create predictions \n\n#plot the hospitalization rate predictions compared to the true observed value\nprediction_plot &lt;- ggplot(data = predictions, mapping = aes(x = .fitted, y = hosp_per_100k)) +\n  geom_point() +\n  geom_abline(slope = 1, color = \"red\", lwd = 1) + #adds red line that follows what the graph would look like if my predictions perfectly matched the observed values.\n  xlim(20, 70) +\n  annotate(\"text\",\n           x = 67, \n           y = 83, \n           label = \"Line of perfect \\n predictions\",\n           color = \"red\",\n           size = 3.5) +\n  labs(x = \"Predicted Hospitalizations (per 100k)\",\n       y = \"True Hospitalizations (per 100k)\",\n       title = \"Comparing our model predictions to the true value of hospitalizations\",\n       subtitle = \"The model trends in the right direction, but tends to over predict low hospitalization rates \\n and underpredict low hospitalization rates. A perfect model would follow the line in red.\") +\n  theme_classic()\n\nprediction_plot\n\n\n\n\n\n\n\n\n\nIn order to further test the effect of wildfires on asthma, I performed a t-test (alpha &lt; 0.05) to compare the mean hospitalization rate caused by asthma in 2016 and 2018. For context, 2016 was a relatively light year for wildfires, with 669,534 acres burnt; in comparison, almost three times as many acres (1,975,086) burned in 2018 [14]. Seeing if there is a difference in the hospitalization rate between these two years could demonstrate the effect of wildfires on asthma hospitalizations. \nThe null hypothesis: There is no difference in the mean hospitalization rate between 2016 and 2018. \n\n\\(H_0:\\mu_{hosp2016} - \\mu_{hosp2018} = 0\\)\n\nThe alternative hypothesis: This is a difference in the mean hospitalization rate between 2016 and 2018.\n\n\\(H_A:\\mu_{hosp2016} - \\mu_{hosp2018} \\neq 0\\) \n\nMy t-test concluded that there is not enough evidence to reject the null hypothesis (t = -0.18629, p = 0.8526). This indicates that, if there was a true difference in the mean hospitalization rate, we’d expect to find a difference in means as extreme as ours 85% of the time. This aligns with the regression model conducted above, but does not align with previous research that smoke from wildfires increases cases of severe asthma [13]. \nHowever, it is important to note that this result does not mean that the total acreage of wildfires burnt has no effect on asthma hospitalizations. It’s possible that the location of the fire and other factors, such as wind patterns and population density near the fire, are affecting the result. Further research could look into the spatial relationship between fires and where asthma related hospitalizations occur.\n\n\n\nCode\n## Hypothesis test that hospitalizations would be different (likely higher) in 2018 than in 2016 due to increased fire acreage burnt. \n\n#2016: 669,534 burnt\n#2018:  1,975,086 burnt\n\nhosp_2016_2018 &lt;- hosp_full %&gt;%\n  filter(year == 2016 | year == 2018) %&gt;%\n  mutate(year = as.factor(year))\n\nfire_test &lt;- t.test(hosp_per_100k ~ year, data = hosp_2016_2018)\n\nfire_test_table &lt;- tab_model(fire_test,\n          string.ci = c(\"Conf. Int (95%)\"),\n          string.p = \"P-value\",\n          dv.labels = c(\"Hospitalization Rate\"),\n          pred.labels = \"2016 – 2018\",\n          title = \"Table 2: Hospitalization Rate and Wildfires: Welch Two Sample t-test\")\n\nfire_test_table\n\n\n\n\nTable 2: Hospitalization Rate and Wildfires: Welch Two Sample t-test\n\n\n \nHospitalization Rate\n\n\nPredictors\nEstimates\nConf. Int (95%)\nP-value\n\n\n2016 – 2018\n-0.51\n-5.94 – 4.92\n0.853\n\n\n\n\n\n\n\n\n\n\nCode\n#Creating a beeswarm plot with boxplot overlay to show distribution of county level mean hospitalization rates for 2016 and 2018. \n\nbeeswarm_boxplot &lt;- ggplot(data = hosp_2016_2018, mapping = aes(x = year, y = hosp_per_100k)) +\n  geom_beeswarm(color = \"red\", alpha = .5) + \n  geom_boxplot(alpha = 0.3) +\n  theme_classic() +\n  labs(x = \"Year\",\n       y = \"Hospitalizations (per 100k)\",\n       title = \"California County Hospitalization Rate from Asthma in 2016 and 2018\",\n       subtitle = \"The distribution of hospitalization rates appear similar from 2016 and 2018\")\n\n#add in t-test and p value to the plot\nbeeswarm_boxplot_t_test &lt;- beeswarm_boxplot + \n  stat_compare_means(method = \"t.test\", label.x = 1.35, label.y = 65)\n\nbeeswarm_boxplot_t_test"
  },
  {
    "objectID": "posts/2022-12-03-asthma-blog/index.html#conclusions",
    "href": "posts/2022-12-03-asthma-blog/index.html#conclusions",
    "title": "Modeling Asthma Hospitalizations",
    "section": "Conclusions",
    "text": "Conclusions\nWhile this research is an important step in exploring the effect of air quality on hospitalizations from asthma in California counties, there are a number of limitations of this analysis that could be addressed in future research. \nIf possible, further analysis should explore the temporal relation between air quality and hospitalizations from asthma on a more granular scale. I was only able to obtain hospitalization data at an annual scale, which made it harder to see how shorter spikes in poor air quality affected asthma related hospitalizations, if at all. \nIt would also be worth exploring a similar analysis but at the census tract, rather than county level. Counties are sufficiently large that the air quality is likely not uniformly distributed throughout. Furthermore, focusing on census tracts could open up the possibility of exploring income in more detail. Our results indicated that higher income averages were associated with lower hospitalization rates from asthma. It’s possible that this finding would be even more pronounced at the census tract, rather than county level. \nThis analysis also has important implications for environmental justice. As mentioned in the introduction, asthma is a disease that affects humans across the globe but more acutely in developing countries. Looking at the World Health Organization’s data for the death rate per 100,000 due to asthma, Kiribati, New Guinea, and Lesotho have rates of 75.4, 47.6, and 45.3, respectively (compared to the US rate of 0.84) [15]. While much of this inequality can likely be attributed to a difference in access to medicine, it is worth exploring what other factors, including air pollution, could be causing such high rates of severe asthma in certain countries. Partnering with researchers in nations where asthma is particularly severe could help address the disparity in prevalence, hospitalization, and death rates across the globe. \nTo summarize, this research examines a number of factors that relate to hospitalizations from severe asthma. From this analysis, it’s clear that clean air is pertinent to preventing severe asthma flare-ups. Given the potential severity of asthma and its prevalence in the US and across the globe, further research should examine this topic to better understand the primary factors that lead to the most severe cases of asthma.\n\nReferences\n[1] “Asthma - Symptoms and causes,” Mayo Clinic. https://www.mayoclinic.org/diseases-conditions/asthma/symptoms-causes/syc-20369653 (accessed Dec. 03, 2022).\n[2] “Asthma.” https://www.who.int/news-room/fact-sheets/detail/asthma (accessed Dec. 02, 2022).\n[3] “Most Recent National Asthma Data | CDC,” May 26, 2022. https://www.cdc.gov/asthma/most_recent_national_asthma_data.htm (accessed Dec. 02, 2022).\n[4] O. US EPA, “The Links Between Air Pollution and Childhood Asthma,” Oct. 22, 2018. https://www.epa.gov/sciencematters/links-between-air-pollution-and-childhood-asthma (accessed Dec. 04, 2022).\n[5] “AirData website File Download page,” United States Environmental Protection Agency. https://aqs.epa.gov/aqsweb/airdata/download_files.html (accessed Dec. 02, 2022).\n[6] “Asthma Prevalence - California Health and Human Services Open Data Portal,” CHHS Open Data. https://data.chhs.ca.gov/dataset/asthma-prevalence (accessed Dec. 02, 2022).\n[7] “Asthma Hospitalization Rates by County - California Health and Human Services Open Data Portal,” CHHS Open Data. https://data.chhs.ca.gov/dataset/asthma-hospitalization-rates-by-county (accessed Dec. 02, 2022).\n[8] “CA Geographic Boundaries - California Open Data,” California Open Data Portal. https://data.ca.gov/dataset/ca-geographic-boundaries (accessed Dec. 02, 2022).\n[9] “wildfire_smoke — ECHO: Environmental Change and Human Outcomes Lab | Stanford University,” ECHO:  Environmental Change and Human Outcomes Lab    |    Stanford University. https://www.stanfordecholab.com/wildfire_smoke (accessed Dec. 02, 2022).\n[10] R. Whitcomb, J. M. Choi, and B. Guan, “CORGIS Datasets Project,” County Demographics CSV File. https://corgis-edu.github.io/corgis/csv/county_demographics/ (accessed Dec. 02, 2022).\n[11] “Data tidying.” Accessed: Dec. 04, 2022. [Online]. Available: https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html\n[12] R. statistics for P. Science, “Choose model variables by AIC in a stepwise algorithm with the MASS package in R,” R Functions and Packages for Political Science Analysis, Oct. 22, 2020. https://rforpoliticalscience.com/2020/10/23/choose-model-variables-by-aic-in-a-stepwise-algorithm-with-the-mass-package-in-r/ (accessed Dec. 04, 2022).\n[13] D. Kiser et al., “Particulate matter and emergency visits for asthma: a time-series study of their association in the presence and absence of wildfire smoke in Reno, Nevada, 2013–2018,” Environ. Health, vol. 19, no. 1, p. 92, Aug. 2020, doi: 10.1186/s12940-020-00646-2.\n[14] “California Wildfires History & Statistics | Frontline Wildfire Defense,” Frontline, Sep. 30, 2020. https://www.frontlinewildfire.com/wildfire-news-and-resources/california-wildfires-history-statistics/ (accessed Dec. 04, 2022).\n[15] “ASTHMA DEATH RATE BY COUNTRY,” World Life Expectancy. https://www.worldlifeexpectancy.com/cause-of-death/asthma/by-country/ (accessed Dec. 05, 2022).\n\n\nSupporting figures\nGithub repository: https://github.com/lewis-r-white/lewis-r-white.github.io\n\n\nCode\n#log max aqi on percent hosp rate\nggplot(data = hosp_full, aes(x = log(max_aqi), y = hosp_per_100k)) +\n  geom_point() +\n  theme_classic() +\n  labs(x = \"Log Max AQI\",\n       y = \"Hospitalization Rate (per 100,000)\",\n       title = \"Checking linearity of log max AQI\")\n\n\n\n\n\n\n\n\n\nCode\nmax_aqi_mod &lt;- lm(hosp_per_100k ~ log(max_aqi), data = hosp_full)\n\nres_max_aqi &lt;- resid(max_aqi_mod)\n\nplot(fitted(max_aqi_mod), res_max_aqi) +\n  abline(0,0) +\n  title(\"Residual plot for max AQI\") # appears fairly linear, although the residuals in the middle are more extreme than at the ends. Proceed with caution. \n\n\n\n\n\n\n\n\n\ninteger(0)\n\n\nCode\n# pop density on hosp rate\nggplot(data = hosp_full, aes(x = log(pop_density_sq_m), y = hosp_per_100k)) +\n  geom_point() +\n  theme_classic() +\n  labs(x = \"Log Population Density\",\n       y = \"Hospitalization Rate (per 100,000)\",\n       title = \"Checking linearity of log population density\")\n\n\n\n\n\n\n\n\n\nCode\npop_density_mod &lt;- lm(hosp_per_100k ~ log(pop_density_sq_m), data = hosp_full)\n\nres_pop_density &lt;- resid(pop_density_mod)\n\nplot(fitted(pop_density_mod), res_pop_density) +\n  abline(0,0) +\n  title(\"Residual plot for log population density\")\n\n\n\n\n\n\n\n\n\ninteger(0)\n\n\nCode\n## median income on hosp\nggplot(data = hosp_full, aes(x = median_income_in_thousands, y = hosp_per_100k)) +\n  geom_point() +\n  theme_classic() +\n  labs(x = \"Median Income (in 1000s)\",\n       y = \"Hospitalization Rate (per 100,000)\",\n       title = \"Checking linearity of Median Income\")\n\n\n\n\n\n\n\n\n\nCode\nincome_mod &lt;- lm(hosp_per_100k ~ median_income_in_thousands, data = hosp_full)\n\nres_income &lt;- resid(income_mod)\n\nplot(fitted(income_mod), res_income) +\n  abline(0,0) +\n  title(\"Residual plot for median income shows some light fanning\") # a little bit of fanning ~ proceed with caution\n\n\n\n\n\n\n\n\n\ninteger(0)\n\n\nCode\n## mean PM 2.5 from fire\nggplot(data = hosp_full, aes(x = sqrt(mean_smokePM), y = hosp_per_100k)) +\n  geom_point() +\n  theme_classic() +\n  labs(x = \"Square Root of Mean Smoke (PM 2.5)\",\n       y = \"Hospitalization Rate (per 100,000)\",\n       title = \"Checking linearity of Mean Smoke\")\n\n\n\n\n\n\n\n\n\nCode\nsmoke_mod &lt;- lm(hosp_per_100k ~ sqrt(mean_smokePM), data = hosp_full)\n\nres_smoke &lt;- resid(smoke_mod)\n\nplot(fitted(smoke_mod), res_smoke) +\n  abline(0,0) +\n  title(\"Residual plot for mean smoke shows some light fanning\") # a little bit of fanning ~ proceed with caution\n\n\n\n\n\n\n\n\n\ninteger(0)"
  },
  {
    "objectID": "posts/2024-05-03-survey-raking/index.html",
    "href": "posts/2024-05-03-survey-raking/index.html",
    "title": "Raking to Improve Survey Weights",
    "section": "",
    "text": "Surveys are an essential tool for gathering information and understanding public opinion on various issues. The success of survey-based research largely depends on the sampling procedure used. When sampling units do not have equal probabilities of selection, survey weights become crucial to ensure that statistics derived from the sample accurately represent the target population.\nTypically, a survey weight for each unit is calculated as the inverse of its probability of being selected. In a simple random sample, this would be 1/N, where N is the total population size, making the weight uniform across all units. However, more complex survey designs—such as stratified, clustered, or multistage sampling—require different weights since each unit may represent varying numbers of people from the target population.\nEven with accurately calculated initial weights, the sample might not perfectly reflect the population due to the inherent randomness of sampling, or factors like non-response or coverage biases. To address these discrepancies, sample weights can be adjusted to better align with known population totals. This process, known as sample balancing, will be further explored with a focus on a specific technique called ‘raking’ in the next section."
  },
  {
    "objectID": "posts/2024-05-03-survey-raking/index.html#raking-steps",
    "href": "posts/2024-05-03-survey-raking/index.html#raking-steps",
    "title": "Raking to Improve Survey Weights",
    "section": "Raking steps:",
    "text": "Raking steps:\n\nTake each row in turn and multiply each entry in the row by the ratio of the population total to the weighted sample total for that category\n\nThe row totals of the adjusted data should agree with the population totals for that variable. The weighted column totals of the adjusted data, however, may not yet agree with the population totals for the column variable.\n\nTake each column and multiply each entry in the column by the ratio of the population total to the current total for that category.\n\nNow the weighted column totals of the adjusted data agree with the population totals for that variable, but the new weighted row totals may no longer match the corresponding population totals.\n\nContinue alternating between the rows and the columns.\n\nClose agreement on both rows and columns is usually achieved after a small number of iterations.\n\nThe result is a tabulation for the population that reflects the relation of the two control variables in the sample.\nRaking can also adjust a set of data to control totals on three or more variables. In such situations the control totals often involve single variables, but they may involve two or more variables."
  },
  {
    "objectID": "posts/2024-05-03-survey-raking/index.html#simple-raking-example-1",
    "href": "posts/2024-05-03-survey-raking/index.html#simple-raking-example-1",
    "title": "Raking to Improve Survey Weights",
    "section": "Simple Raking Example",
    "text": "Simple Raking Example\n\n\n\n\nChild\nAdult\nRow Total\n\n\n\n\nUrban\n30\n20\n50\n\n\nRural\n20\n30\n50\n\n\nColumn Total\n50\n50\n100\n\n\n\nDesired population totals:\n\nUrban: 60, Rural: 40\nChild: 40, Adult: 60\n\n\nAdjusting the rows first to match the locality population totals:\n\nUrban adjustment ratio: 60 / 50 = 1.2\nRural adjustment ratio: 40 / 50 = 0.8\n\nAdjusted rows:\n\n\n\n\nChild\nAdult\nRow Total\n\n\n\n\nUrban\n36\n24\n60\n\n\nRural\n16\n24\n40\n\n\nColumn Total\n52\n48\n100\n\n\n\nNow, the row totals match the population totals for locality. However, the column totals for age groups are still off.\nAdjusting columns to match the age group population totals:\n\nChild adjustment ratio: 40 / 52 ≈ 0.7692\nAdult adjustment ratio: 60 / 48 = 1.25\n\nAdjusted columns:\n\n\n\n\nChild\nAdult\nRow Total\n\n\n\n\nUrban\n27.69\n30\n57.69\n\n\nRural\n12.31\n30\n42.31\n\n\nColumn Total\n40\n60\n100\n\n\n\n \nReadjusting the rows to match the locality population totals:\n\nUrban adjustment ratio: 60 / 57.69 = 1.04\nRural adjustment ratio: 40 / 42.31 = 0.945\n\nAdjusted rows:\n\n\n\n\nChild\nAdult\nRow Total\n\n\n\n\nUrban\n28.80\n31.20\n60\n\n\nRural\n11.61\n28.36\n40\n\n\nColumn Total\n40.44\n59.56\n100\n\n\n\nReadjusting the columns to match the age population totals:\n\nChild adjustment ratio: 40 / 40.44 = 0.989\nAdult adjustment ratio: 60 / 59.56 = 1.007\n\n\n\n\n\nChild\nAdult\nRow Total\n\n\nUrban\n28.49\n31.43\n59.92\n\n\nRural\n11.51\n28.57\n40.08\n\n\nColumn Total\n40\n60\n100\n\n\n\nAt a certain point, the algorithm determines that the marginal populations are “close enough” to the target population — this is convergence. You are able to specify the convergence criterion when setting up the raking procedure. One simple definition of convergence requires that each marginal total of the raked weights be within a specified tolerance of the corresponding control total. In the rake() function in R, convergence is reached if the maximum change in a table entry is less than epsilon (default = 1).\nIt is harder to visualize when raking on more variables, but the process is the same. You continue making adjustments until the marginal sample populations are “close enough” to the target."
  },
  {
    "objectID": "posts/2024-05-03-survey-raking/index.html#background",
    "href": "posts/2024-05-03-survey-raking/index.html#background",
    "title": "Raking to Improve Survey Weights",
    "section": "Background:",
    "text": "Background:\nAs part of the Combating Household Air Pollution (CHAP) project, we applied raking to a national household survey on fuel use in Ghana. The CHAP project is a collaborative effort from several research institutions: Columbia University, UC Santa Barbara, and the Kintampo Health Research Center in Ghana. For the fuel survey, we also partnered with the Ghana Statistical Service to conduct the sampling and interviews.\nThe CHAP survey employed a multistage, cluster approach to the sample. A total of 370 enumeration areas (EAs) and 20 households within each EA were sampled for a total sample size of 7,400 households. Ghana’s 16 regions were used for stratification, as well as the classification of an EA as either urban or rural.\nInitial survey weights were calculated based on the probability of selecting an EA and a household within it. Discrepancies between our survey results and the census data from the Ghana Statistical Services (GSS) prompted us to employ raking to refine our weights."
  },
  {
    "objectID": "posts/2024-05-03-survey-raking/index.html#set-up",
    "href": "posts/2024-05-03-survey-raking/index.html#set-up",
    "title": "Raking to Improve Survey Weights",
    "section": "Set Up:",
    "text": "Set Up:\nWe tested various raking models using the survey package in R, starting with base weights and adjusting for different sets of variables. To address issues with small cell sizes, regional data was consolidated into larger groupings. The process and rationale for these adjustments are detailed below.\n\ny* indicates that the measurement is obtained through the regional cross distribution.\n\n\nStat\nRake 1\nRake 2\nRake 3\nRake 4\n\n\n\n\nTotal urban/rural households\ny\ny*\ny\ny*\n\n\nTotal households in each region\ny\ny*\ny\ny\n\n\nRegional urban/rural households\n\ny\n\ny\n\n\nTotal primary fuel source\n\n\ny\ny*\n\n\nRegional primary fuel source\n\n\n\ny\n\n\n\nExpand the code blocks below to examine how we set up the raking procedure and complete raking for each of these models.\n\nSetting up the Population Totals for Raking\n\n\nCode\n### urban/rural total\npop.urban_rural_str &lt;-\n  data.frame(\n    urban_rural_str = c(\"urban\", \"rural\"),\n    Freq = c(\n      subset(gss, region == \"Total\")$hh_pop_urban,\n      subset(gss, region == \"Total\")$hh_pop_rural\n    )\n  )\n\n### primary fuel categories \n\nhh_pop_tot &lt;- subset(gss, region == \"Total\")$hh_pop\n\nfrac_lpg &lt;- subset(gss, region == \"Total\")$fuel_lpg / subset(gss, region == \"Total\")$hh_pop_fuel\n\nfrac_char &lt;- subset(gss, region == \"Total\")$fuel_char / subset(gss, region == \"Total\")$hh_pop_fuel\n\nfrac_wood &lt;- subset(gss, region == \"Total\")$fuel_wood / subset(gss, region == \"Total\")$hh_pop_fuel\n  \n\npop.primary_fuel &lt;-\n  data.frame(\n    collapsed_fuel = c(\"none_other\", \"wood\", \"LPG\", \"charcoal\"),\n    Freq = c(\n      round((1 - (frac_lpg + frac_wood + frac_char)) * hh_pop_tot, 0),\n      round(frac_wood * hh_pop_tot, 0),\n      round(frac_lpg * hh_pop_tot, 0),\n      round(frac_char * hh_pop_tot, 0)\n    )\n  )\n\n\n### regional 2021 HH populations \ngss_regional &lt;- filter(gss, region != \"Total\") \n\npop.region_hh &lt;- data.frame(\n  region = gss_regional$region,\n  Freq = gss_regional$hh_pop\n)\n\n\n\n\n# regional main fuel \n#specify known main fuel population values for each of the regions \npop.region_main_fuel &lt;- gss_regional %&gt;% \n  mutate(none_other = fuel_none + fuel_other) %&gt;%\n  rename(LPG = fuel_lpg, \n         wood = fuel_wood, \n         charcoal = fuel_char) %&gt;%\n  select(region, none_other, wood, LPG, charcoal) %&gt;%\n  \n  #apply scaling factor so population matches GSS total value\n  mutate(none_other = round(none_other * subset(gss, region == \"Total\")$hh_pop/subset(gss, region == \"Total\")$hh_pop_fuel, 0),\n         LPG = round(LPG * subset(gss, region == \"Total\")$hh_pop/subset(gss, region == \"Total\")$hh_pop_fuel,0),\n         wood = round(wood * subset(gss, region == \"Total\")$hh_pop/subset(gss, region == \"Total\")$hh_pop_fuel, 0),\n         charcoal = round(charcoal * subset(gss, region == \"Total\")$hh_pop/subset(gss, region == \"Total\")$hh_pop_fuel, 0))\n\nnorthern &lt;- pop.region_main_fuel %&gt;%\n  filter(region %in% c(\"Upper East\", \"Upper West\", \"North East\", \"Northern\", \"Savannah\", \"Oti\", \"Bono\", \"Bono East\", \"Ahafo\")) %&gt;%\n  summarise(\n    region = \"northern\",\n    none_other = sum(none_other),\n    wood = sum(wood),\n    LPG = sum(LPG),\n    charcoal = sum(charcoal)\n  )\n\n\nmiddle &lt;- pop.region_main_fuel %&gt;%\n  filter(region %in% c(\"Ashanti\", \"Eastern\")) %&gt;%\n  summarise(\n    region = \"middle\",\n    none_other = sum(none_other),\n    wood = sum(wood),\n    LPG = sum(LPG),\n    charcoal = sum(charcoal)\n  )\n\nsoutheast &lt;- pop.region_main_fuel %&gt;%\n  filter(region %in% c(\"Greater Accra\", \"Volta\")) %&gt;%\n  summarise(\n    region = \"southeast\",\n    none_other = sum(none_other),\n    wood = sum(wood),\n    LPG = sum(LPG),\n    charcoal = sum(charcoal)\n  )\n\nsouthwest &lt;- pop.region_main_fuel %&gt;%\n  filter(region %in% c(\"Central\", \"Western\", \"Western North\")) %&gt;%\n  summarise(\n    region = \"southwest\",\n    none_other = sum(none_other),\n    wood = sum(wood),\n    LPG = sum(LPG),\n    charcoal = sum(charcoal)\n  )\n\ncollapsed_region_primary_fuel &lt;- bind_rows(northern, middle, southeast, southwest)\n\n\n#Combine primary fuel with each row specifying which is applicable \npop_region_primary_fuel_long &lt;- collapsed_region_primary_fuel %&gt;%\n  pivot_longer(cols = c(none_other, wood, LPG, charcoal), names_to = \"collapsed_fuel\", values_to = \"Count\") #names need to match what is in the survey!!\n\n# reformat this data so each row is a household (necessary for creating pop.table below)\npop_region_primary_fuel_long &lt;- pop_region_primary_fuel_long %&gt;%\n  uncount(Count) %&gt;%\n  rename(collapsed_region = region)\n\n#create table of LPG main stove by collapsed regions\npop.table_primary_fuel &lt;- xtabs(~collapsed_region+collapsed_fuel, pop_region_primary_fuel_long)\n\n\n\n\n# regional urbanicity \n#regional 2021 HH populations \npop.region_urban_rural_hh &lt;- gss_regional %&gt;%\n  select(region, hh_pop_rural, hh_pop_urban) %&gt;%\n  rename(rural = hh_pop_rural, \n         urban = hh_pop_urban)\n\n\nnorthern &lt;- pop.region_urban_rural_hh %&gt;%\n  filter(region %in% c(\"Upper East\", \"Upper West\", \"North East\", \"Northern\", \"Savannah\", \"Oti\", \"Bono\", \"Bono East\", \"Ahafo\")) %&gt;%\n  summarise(\n    region = \"northern\",\n    urban = sum(urban),\n    rural = sum(rural)\n  )\n\n\nmiddle &lt;- pop.region_urban_rural_hh %&gt;%\n  filter(region %in% c(\"Ashanti\", \"Eastern\")) %&gt;%\n  summarise(\n    region = \"middle\",\n    urban = sum(urban),\n    rural = sum(rural)\n  )\n\nsoutheast &lt;- pop.region_urban_rural_hh %&gt;%\n  filter(region %in% c(\"Greater Accra\", \"Volta\")) %&gt;%\n  summarise(\n    region = \"southeast\",\n    urban = sum(urban),\n    rural = sum(rural)\n  )\n\nsouthwest &lt;- pop.region_urban_rural_hh %&gt;%\n  filter(region %in% c(\"Central\", \"Western\", \"Western North\")) %&gt;%\n  summarise(\n    region = \"southwest\",\n    urban = sum(urban),\n    rural = sum(rural)\n  )\n\ncollapsed_region_urban_rural_hh &lt;- bind_rows(northern, middle, southeast, southwest)\n\n\n#Combine LPG yes/no columns with each row specifying which is applicable \npop_region_urban_rural_long &lt;- collapsed_region_urban_rural_hh %&gt;%\n  pivot_longer(cols = c(rural, urban), names_to = \"urban_rural_str\", values_to = \"Count\") #names need to match what is in the survey!!\n\n# reformat this data so each row is a household (necessary for creating pop.table below)\npop_region_urban_rural_long &lt;- pop_region_urban_rural_long %&gt;%\n  uncount(Count) %&gt;%\n  rename(collapsed_region = region)\n\n#create table of LPG main stove by collapsed regions\npop.table_urban_rural &lt;- xtabs(~collapsed_region+urban_rural_str, pop_region_urban_rural_long)\n\n\n\n\nSpecifying the Survey Design (using Rake()) for Each of the Models\n\n\nCode\n# Un-weighted\nunweighted_survey_design &lt;- svydesign(id=~eacode, #specify clusters\n                           strata= ~region, #specify the region strata\n                           data=full_survey_collapsed)\n\n#base weights\nsurvey_design &lt;- svydesign(id=~eacode, #specify clusters\n                           weights= ~weight, #specify the survey weights\n                           strata= ~region, #specify the region strata\n                           data=full_survey_collapsed)\n\n\n# Rake 1\nraked_surv &lt;- rake(survey_design, \n                   list(~urban_rural_str, ~region), \n                   list(pop.urban_rural_str, pop.region_hh)\n                   )\n\nupper_weight &lt;- mean(weights(raked_surv, type = \"sampling\")) * 5\n\nrake1_design &lt;- trimWeights(raked_surv, lower=0.1, upper=upper_weight,\n                                   strict = TRUE)\n\n\n#Rake 2\nraked_surv &lt;- rake(survey_design, \n                   list(~urban_rural_str+collapsed_region), \n                   list(pop.table_urban_rural)\n                   )\n\nupper_weight &lt;- mean(weights(raked_surv, type = \"sampling\")) * 5\n\nrake2_design &lt;- trimWeights(raked_surv, lower=0.1, upper=upper_weight,\n                                   strict = TRUE)\n\n\n#Rake 3\nraked_surv &lt;- rake(survey_design, list(~urban_rural_str, ~collapsed_fuel, ~region), list(pop.urban_rural_str, pop.primary_fuel, pop.region_hh), control = list(maxit = 20, epsilon = 1, verbose = FALSE))\n\nupper_weight &lt;- mean(weights(raked_surv, type = \"sampling\")) * 5\n\nrake3_design &lt;- trimWeights(raked_surv, lower=0.1, upper=upper_weight,\n                                   strict = TRUE)\n\n\n#Rake 4\nraked_surv &lt;- rake(survey_design, \n                   list(~urban_rural_str+collapsed_region, ~collapsed_region+collapsed_fuel), \n                   list(pop.table_urban_rural, pop.table_primary_fuel), control = list(maxit = 15, epsilon = 1))\n\nupper_weight &lt;- mean(weights(raked_surv, type = \"sampling\")) * 5\n\nrake4_design &lt;- trimWeights(raked_surv, lower=0.1, upper=upper_weight,\n                                   strict = TRUE)\n\n\n\n\nCalculating the Survey Statistics for Each Model\n\n\nCode\nunweighted &lt;- calculate_survey_stats(unweighted_survey_design, \"unweighted\")\n\nGL_FM &lt;- calculate_survey_stats(survey_design, \"GL_FM\")\n\nrake1 &lt;- calculate_survey_stats(rake1_design, \"rake1\")\n\nrake2 &lt;- calculate_survey_stats(rake2_design, \"rake2\")\n\nrake3 &lt;- calculate_survey_stats(rake3_design, \"rake3\")\n\nrake4 &lt;- calculate_survey_stats(rake4_design, \"rake4\")"
  },
  {
    "objectID": "posts/2024-05-03-survey-raking/index.html#results",
    "href": "posts/2024-05-03-survey-raking/index.html#results",
    "title": "Raking to Improve Survey Weights",
    "section": "Results",
    "text": "Results\nThe effectiveness of each raking model was evaluated by comparing survey results against GSS census data for included variables. Highlighted cells indicate a difference of at least 5 % between the given cell value and the GSS-2021 value. Raking generally enhanced the alignment with GSS values, particularly for variables directly adjusted in the models. The table below outlines the performance metrics across different models.\n\n\nCode\nhigh_level_results &lt;- left_join(GSS_stats, unweighted) %&gt;%\n  left_join(GL_FM) %&gt;%\n  left_join(rake1) %&gt;%\n  left_join(rake2) %&gt;%\n  left_join(rake3) %&gt;%\n  left_join(rake4) %&gt;%\n  mutate(rake1 = as.numeric(rake1),\n         rake2 = as.numeric(rake2),\n         rake3 = as.numeric(rake3),\n         rake4 = as.numeric(rake4)) %&gt;%\n  filter(stat != \"total_households\")\n\n\n#create shaded table of high level results\n\n# Round GSS values to two decimal places\nhigh_level_results$GSS &lt;- round(high_level_results$GSS, 2)\n\n# Calculate bounds with different methods for the first three rows and the rest\nhigh_level_results$lower_bound &lt;- ifelse(1:nrow(high_level_results) &lt;= 3, high_level_results$GSS * 0.95, high_level_results$GSS - 5)\n\nhigh_level_results$upper_bound &lt;- ifelse(1:nrow(high_level_results) &lt;= 3, high_level_results$GSS * 1.05, high_level_results$GSS + 5)\n\n# Create the datatable with custom JS for highlighting and hide lower and upper bound columns\ndatatable(high_level_results, options = list(\n  rowCallback = JS(\"\n    function(row, data) {\n      for (var i = 2; i &lt; data.length-2; i++) {\n        var lowerBound = parseFloat(data[data.length-2]);\n        var upperBound = parseFloat(data[data.length-1]);\n        var cellValue = parseFloat(data[i]);\n        if (cellValue &lt; lowerBound || cellValue &gt; upperBound) {\n          $('td:eq('+i+')', row).css('background-color', '#ff9999');\n        }\n      }\n    }\"\n  ),\n  columnDefs = list(list(visible = FALSE, targets = c(ncol(high_level_results)-1, ncol(high_level_results))))\n))"
  },
  {
    "objectID": "posts/2024-05-03-survey-raking/index.html#conclusions",
    "href": "posts/2024-05-03-survey-raking/index.html#conclusions",
    "title": "Raking to Improve Survey Weights",
    "section": "Conclusions",
    "text": "Conclusions\nAs expected, we found that the raking process consistently improved alignment with GSS values for raked variables. For statistics where the variable was not included in the raking process, we found the results sometimes better aligned post-raking and never became concerningly worse.\nAs the statistics for variables not used in the raking process tended to remain stable or improved slightly in the version of our raking model that utilized the most information in the set up (rake 4), we decided to move ahead with that model. Additional sensitivity analysis was conducted to examine the stability of the results when using different regional groupings."
  },
  {
    "objectID": "posts/2024-05-03-survey-raking/index.html#sensitivity-analysis-grouping-variations",
    "href": "posts/2024-05-03-survey-raking/index.html#sensitivity-analysis-grouping-variations",
    "title": "Raking to Improve Survey Weights",
    "section": "Sensitivity Analysis: Grouping Variations",
    "text": "Sensitivity Analysis: Grouping Variations\nWe explored different regional groupings to ensure robust model performance without convergence issues. Grouping strategies were informed by demographic similarities and household population sizes, ensuring meaningful comparisons and reliable raking results.\n\n\nCode\nggplot() +\n  geom_sf(data = regions, aes(fill = region)) +\n  theme_minimal() +\n  labs(fill = \"Region\",\n       title = \"Regions of Ghana\")+\n  theme(plot.title = element_text(size = 20)) +\n  theme(\n    axis.text = element_blank(),  # Remove axis text\n    axis.title = element_blank(),  # Remove axis titles\n    panel.grid = element_blank()\n  )\n\n\n\n\n\n\n\n\n\nCode\nrake1_regions &lt;- regions %&gt;%\n  mutate(collapsed_region = case_when(\n  region %in% c(\"Ashanti\", \"Eastern\") ~ \"middle\",\n  region %in% c(\"Upper East\", \"Upper West\", \"Northern East\", \"Northern\", \"Savannah\", \"Oti\", \"Bono\", \"Bono East\", \"Ahafo\") ~ \"northern\",\n  region %in% c(\"Greater Accra\", \"Volta\") ~ \"southeast\",\n  region %in% c(\"Central\", \"Western\", \"Western North\") ~ \"southwest\",\n  TRUE ~ region)) %&gt;%\n  mutate(collapsed_region = factor(collapsed_region, levels = c(\"northern\", \"middle\", \"southeast\", \"southwest\")))\n\n# Define custom colors for each region\ncustom_colors &lt;- c(\"middle\" = \"#2b8f6d\", \n                   \"northern\" = \"#58b368\", \n                   \"southeast\" = \"#bcba50\", \n                   \"southwest\" = \"#EFEEB4\"\n                   )\n\nggplot() +\n  geom_sf(data = rake1_regions, aes(fill = collapsed_region)) +\n  scale_fill_manual(values = custom_colors) +\n  theme_minimal() +\n  labs(fill = \"Region\",\n       title = \"Rake 4a Collapsed Regions\") +\n  theme(plot.title = element_text(size = 20)) +\n  theme(\n    axis.text = element_blank(),  # Remove axis text\n    axis.title = element_blank(),  # Remove axis titles\n    panel.grid = element_blank()\n  )\n\n\n\n\n\n\n\n\n\nCode\nrake2_regions &lt;- regions %&gt;%\n  mutate(collapsed_region = case_when(\n  region %in% c(\"Ashanti\", \"Eastern\") ~ \"middle\",\n  region %in% c(\"Upper East\", \"Upper West\", \"Northern East\", \"Northern\", \"Savannah\", \"Oti\", \"Western North\", \"Bono\", \"Bono East\", \"Ahafo\") ~ \"northern\",\n  region %in% c(\"Greater Accra\", \"Volta\", \"Central\", \"Western\") ~ \"coastal\",\n  TRUE ~ region)) %&gt;%\n  mutate(collapsed_region = factor(collapsed_region, levels = c(\"northern\", \"middle\", \"coastal\")))\n\n# Define custom colors for each region\ncustom_colors &lt;- c(\"middle\" = \"#2b8f6d\", \n                   \"northern\" = \"#58b368\", \n                   \"coastal\" = \"#EFEEB4\"\n                   )\n\nggplot() +\n  geom_sf(data = rake2_regions, aes(fill = collapsed_region)) +\n  scale_fill_manual(values = custom_colors) +\n  theme_minimal() +\n  labs(fill = \"Region\",\n       title = \"Rake 4b Collapsed Regions\") +\n  theme(plot.title = element_text(size = 20)) +\n  theme(\n    axis.text = element_blank(),  # Remove axis text\n    axis.title = element_blank(),  # Remove axis titles\n    panel.grid = element_blank()\n  )\n\n\n\n\n\n\n\n\n\nCode\nrake3_regions &lt;- regions %&gt;%\n  mutate(collapsed_region = case_when(\n  region %in% c(\"Ashanti\", \"Eastern\", \"Volta\") ~ \"middle\",\n  region %in% c(\"Upper East\", \"Upper West\", \"Northern East\", \"Northern\", \"Savannah\", \"Oti\", \"Western North\", \"Bono\", \"Bono East\", \"Ahafo\") ~ \"northern\",\n  region %in% c(\"Greater Accra\", \"Central\", \"Western\") ~ \"coastal\",\n  TRUE ~ region)) %&gt;%\n  mutate(collapsed_region = factor(collapsed_region, levels = c(\"northern\", \"middle\", \"coastal\")))\n\n# Define custom colors for each region\ncustom_colors &lt;- c(\"middle\" = \"#2b8f6d\", \n                   \"northern\" = \"#58b368\", \n                   \"coastal\" = \"#EFEEB4\"\n                   )\n\nggplot() +\n  geom_sf(data = rake3_regions, aes(fill = collapsed_region)) +\n  scale_fill_manual(values = custom_colors) +\n  theme_minimal() +\n  labs(fill = \"Region\",\n       title = \"Rake 4c Collapsed Regions\") +\n  theme(plot.title = element_text(size = 20)) +\n  theme(\n    axis.text = element_blank(),  # Remove axis text\n    axis.title = element_blank(),  # Remove axis titles\n    panel.grid = element_blank()\n  )"
  },
  {
    "objectID": "posts/2024-05-03-survey-raking/index.html#sensitivity-analysis-results",
    "href": "posts/2024-05-03-survey-raking/index.html#sensitivity-analysis-results",
    "title": "Raking to Improve Survey Weights",
    "section": "Sensitivity Analysis: Results",
    "text": "Sensitivity Analysis: Results\nThe table below shows the results from our sensitivity analysis and follows a similar format to the previous table. Here, the statistics are broken up by variables used in the raking process and those that were not.\n\nOverall, the results from the sensitivity analysis showed stability across the three groupings. Based on this, the team in Ghana decided which groupings of regions made the most sense based on knowledge of the regions, selecting 4a as their preferred model."
  },
  {
    "objectID": "posts/2022-05-01-video-quality-dscout/index.html",
    "href": "posts/2022-05-01-video-quality-dscout/index.html",
    "title": "Testing How To Improve Video Response Quality in Remote Research",
    "section": "",
    "text": "Introduction\nOne of the best aspects of dscout’s remote research platform is the ability to ask the study participants—affectionately called “scouts”—to record and share videos. These videos were used for a vast array of purposes, such as capturing in-the-moment tasks, real-time reactions to products, and encouraging rich responses to complex research questions. Here are a few examples from study designs I crafted for clients:\n\nFor a project about getting new users to try a brand’s breakfast food item for the first time.\n“We want your immediate, unfiltered first reactions to {breakfast food item}! Please record a short video (about 60 seconds) as you take your first bite. As you taste it, tell us:\n• How would you describe the flavor?\n• What do you notice about the texture?\n• After trying it, would you purchase it again—and why or why not?”\n\nFor a project about a workplace productivity tool to help a major technology corporation improve the accessibility of its product. Scouts with certain disabilities were recruited for this study, and at least three entries were required for this question.\n\n“Show us how you use {tool} in your daily workflow. In a 2-3 minute video (for each task or use case), please screen share or capture your screen as you walk us through:\n• The Task: What are you trying to accomplish with {tool}?\n• Your Process: Which features are you using, and why?\n• Your Feedback: What do you love about this process? Where do you get stuck or feel frustrated?\n• Your Wishlist: If you could improve one thing about {tool} for this specific task, what would it be?”\nFor a project about scout’s fitness journey to help an online exercise app design a better experience for their users.\n\n“In a short video (1–2 minutes), please describe why fitness is or is not important to you. Then, reflect on how fitness fits into (or clashes with) your daily routine, habits, and priorities.”\n\nThese videos all led clients towards actionable changes that improved products and experiences. However, for one project, the client was looking for more than just insights about the research question. They were creating a website on a fairly rare medical condition and were hoping to include testimonials from our scouts on their website—if granted permission of course!\nThe client repeatedly emphasized the importance of high-quality, professional-looking videos. While the video prompts in dscout’s platform include brief instructions on how to record and upload a video, I drafted additional instructions and suggestions for this diary-style study. As the medical condition could sometimes lead to shaky hands, I suggested asking a helper to take the video or using a prop to ensure a professional quality video. I also described what a good video would look and sound like, and included example images to help our scouts know how to position themselves in relation to the camera—angle, zoom, lighting, etc.\nThe client was thrilled with the quality of the videos that still captured the authentic feeling of an everyday individual living with the disease. From watching the videos myself, it felt like the quality was elevated compared to the standard scout video. I was curious if this was really the case and wanted to test it using dscout’s video quality automated sensors, which measure the verbal richness (the length and varied word choices of the response), luminosity (the lighting in the video), and shakiness of the video.\nEven for videos used solely for internal research, the quality of user-submitted content directly affects the depth of insights we can generate. By improving video responses, we ensure that research participants’ voices are clearer, more detailed, and more actionable for product teams to design better experiences. Given the additional effort required from participants to follow detailed instructions, I wanted to test whether these extra steps meaningfully improved video quality—and if the trade-off was worth it.\nTo accomplish this, I’d need to run a new study with a more general recruitment population and include the exact same video question prompt for all the study participants, I proposed a brief study on what scouts like most about dscout and secured funding to proceed. I drafted the study design to include 3 treatment groups, outlined below.\n1) Control Group: Received dscout’s standard video instructions.\n2) Additional Instructions Group: Included the standard instructions along with a multiple select style question that required all boxes to be ticked before moving on. The instructions are detailed below:\n• You’re the expert! Remember to explain your thought process and go into as much detail as possible in your response.\n• Make sure your phone is steady as you record.\n\n• Please remember to record your video in a well-lit space.\n3) Additional Instructions + Example Group: Included the standard instructions, the multiple select style question above with additional instruction, and an example image to show what the final video should look like in terms of angle and lighting.\nFor the sample, I created a screener with minimal knockout criteria to recruit scouts representative of the general scout pool. I selected 100 scouts, aiming for at least 30 in each treatment group completing the study, and stratified by dscout experience to ensure that all of the seasoned dscout users didn’t randomly end up in the same treatment arm.\nOnce the fieldwork for the study ended, it was time to test my theory, with the null hypothesis being that the additional instructions do not improve video quality and the alternate hypothesis that they do improve video quality.\nPlease note: While I can’t share the actual results due to confidentiality, I’ve generated example data to illustrate the analysis. The below example includes data I generated to communicate the analysis process.\n\n\nResults\nThe boxplot below illustrates how video quality metrics (luminosity, shakiness, and verbal richness) vary across the three treatment groups. Each box represents the distribution of values, with the median marked by the central line. By comparing these distributions, we can visually assess whether additional instructions led to improvements in video quality.\n\n\nCode\nvideo_qual_df %&gt;%\n  pivot_longer(cols = c(luminosity, shakiness, \"verbal richness\"), names_to = \"metric\") %&gt;%\n  ggplot(aes(x = group, y = value, fill = group)) + \n  geom_boxplot() +\n  facet_wrap(~metric) +\n  theme_bw() +\n  labs(x = \"Treatment Group\", y = \"Metric Score\", title = \"Boxplots Indicate Instruction Treatment Groups Improved Video Quality\") +\n  scale_x_discrete(labels = c(\n    \"control\" = \"Control\", \n    \"instructions\" = \"Instructions\", \n    \"instructions + example\" = \"Instructions \\n+ Example\"\n  )) +\n  theme(legend.position = \"none\")  +\n  scale_fill_brewer(palette=\"BuPu\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 0.5, vjust = 0.5))\n\n\n\n\n\n\n\n\n\nTo statistically test whether video quality metrics differ across treatment groups, I conducted a one-way ANOVA for each metric. If significant differences are found, this indicates that at least one group differs from the others.\n\n\nCode\n# Run ANOVA for each metric\n\n# luminosity \nanova_luminosity &lt;- oneway.test(luminosity ~ group, data = video_qual_df, var.equal = TRUE)\nprint(anova_luminosity)\n\n\n\n    One-way analysis of means\n\ndata:  luminosity and group\nF = 21.463, num df = 2, denom df = 97, p-value = 1.916e-08\n\n\nCode\n# shakiness\nanova_shakiness &lt;- oneway.test(shakiness ~ group, data = video_qual_df, var.equal = FALSE)  # Welch’s ANOVA because unequal variance\nprint(anova_shakiness)\n\n\n\n    One-way analysis of means (not assuming equal variances)\n\ndata:  shakiness and group\nF = 31.371, num df = 2.000, denom df = 58.046, p-value = 5.799e-10\n\n\nCode\n# Verbal richness\nanova_verbal &lt;- oneway.test(`verbal richness` ~ group, data = video_qual_df, var.equal = TRUE)\nprint(anova_verbal)\n\n\n\n    One-way analysis of means\n\ndata:  `verbal richness` and group\nF = 7.1451, num df = 2, denom df = 97, p-value = 0.001274\n\n\nSince the ANOVA results indicate significant differences across groups, I conducted pairwise t-tests to determine which specific groups differ from each other.\n\n\nCode\n# Pairwise t-tests \n# Format pairwise test results, replacing p-values &lt;0.001 with \"&lt;0.001\"\npairwise_tests &lt;- video_qual_df %&gt;%\n  pivot_longer(cols = c(luminosity, shakiness, `verbal richness`), names_to = \"metric\") %&gt;%\n  group_by(metric) %&gt;%\n  summarise(\n    control_vs_instructions = if_else(metric == \"shakiness\",\n                                       t.test(value[group == \"control\"], value[group == \"instructions\"], var.equal = FALSE)$p.value,\n                                       t.test(value[group == \"control\"], value[group == \"instructions\"], var.equal = TRUE)$p.value),\n    control_vs_example = if_else(metric == \"shakiness\",\n                                 t.test(value[group == \"control\"], value[group == \"instructions + example\"], var.equal = FALSE)$p.value,\n                                 t.test(value[group == \"control\"], value[group == \"instructions + example\"], var.equal = TRUE)$p.value),\n    instructions_vs_example = if_else(metric == \"shakiness\",\n                                      t.test(value[group == \"instructions\"], value[group == \"instructions + example\"], var.equal = FALSE)$p.value,\n                                      t.test(value[group == \"instructions\"], value[group == \"instructions + example\"], var.equal = TRUE)$p.value)\n  ) %&gt;%\n  distinct() %&gt;%\n  mutate(across(where(is.numeric), ~ ifelse(. &lt; 0.001, \"&lt;0.001\", format(round(., 3), nsmall = 3))))  # Replace small values\n\n# Print formatted table with clearer column names\npairwise_tests %&gt;%\n  kable(\n    col.names = c(\n      \"Metric\", \n      \"Control vs. Instructions (p-value)\", \n      \"Control vs. Example (p-value)\", \n      \"Instructions vs. Example (p-value)\"\n    ),\n    caption = \"Pairwise T-Test Results for Video Quality Metrics\"\n  )\n\n\n\nPairwise T-Test Results for Video Quality Metrics\n\n\n\n\n\n\n\n\nMetric\nControl vs. Instructions (p-value)\nControl vs. Example (p-value)\nInstructions vs. Example (p-value)\n\n\n\n\nluminosity\n&lt;0.001\n&lt;0.001\n0.011\n\n\nshakiness\n&lt;0.001\n&lt;0.001\n&lt;0.001\n\n\nverbal richness\n&lt;0.001\n0.015\n0.292\n\n\n\n\n\nThe results revealed clear differences across the metrics:\nLuminosity\n\nVideos recorded by participants in the Instructions group (µ = 0.74) and Instructions + Example group (µ = 0.80) were significantly brighter than those in the Control group (µ = 0.65, p &lt; 0.001 for each).\nThe Instructions + Example group also had significantly higher luminosity scores than the Instructions group (p = 0.011).\nThese results suggest that even minimal guidance improves lighting conditions, and including an example image further enhances video brightness.\n\nShakiness\n\nThe Control group had the highest shakiness scores (µ = 0.20), indicating less stable video recordings.\nBoth the Instructions (µ = 0.11) and Instructions + Example (µ = 0.07) groups significantly reduced shakiness compared to the Control group (p &lt; 0.001 for each).\nAdditionally, the Instructions + Example group achieved greater stability than the Instructions group (p &lt; 0.001).\nThis suggests that even simple reminders improve video steadiness, and an example further reinforces proper recording techniques.\n\nVerbal Richness\n\nParticipants in the Instructions group (µ = 0.79) used significantly more varied and verbose language than those in the Control group (µ = 0.69, p &lt; 0.001).\nThe Instructions + Example group (µ = 0.76) also showed an improvement over the Control group (p = 0.015), though the difference between the Instructions and Instructions + Example groups was not statistically significant (p = 0.292).\nThis suggests that additional instructions alone encourage richer verbal responses, while the example image may not contribute as much to this specific aspect.\n\n\n\nConclusions\nThis experiment provides a research-backed recommendation for designing remote video tasks: clear, structured instructions significantly improve video quality. By applying similar structured guidance to other research methods—such as mobile diary studies or self-reported usability tests—UX researchers can ensure richer, more actionable user insights. For UX teams conducting remote research, these findings suggest that small, well-placed instructions can significantly improve response quality—without requiring complex interventions or additional moderation.\nI presented these results to the team at an all-company meeting, and many other research advisors at dscout used the additional instructions I crafted for their clients.\nAlong with the video findings, the scouts’ awesome videos allowed me to create a fun compilation of the scouts sharing their love for dscout that was shared in the holiday party.\n\n\n\n\nCitationBibTeX citation:@online{white2022,\n  author = {White, Lewis},\n  title = {Testing {How} {To} {Improve} {Video} {Response} {Quality} in\n    {Remote} {Research}},\n  date = {2022-05-01},\n  url = {https://lewis-r-white.github.io/posts/2022-05-01-video-quality-dscout/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nWhite, Lewis. 2022. “Testing How To Improve Video Response Quality\nin Remote Research.” May 1, 2022. https://lewis-r-white.github.io/posts/2022-05-01-video-quality-dscout/."
  },
  {
    "objectID": "posts/2023-03-13-spotify-ML-blog/index.html",
    "href": "posts/2023-03-13-spotify-ML-blog/index.html",
    "title": "Whose Song is it Anyway?",
    "section": "",
    "text": "Have you ever wondered how your music taste compares to your friends’? Or perhaps you’re just curious about how your favorite songs and artists and genres stack up against your peers. As a music lover, I enjoy discussing these topics and was thrilled when an assignment for my machine learning course involved analyzing Spotify data. For the assignment, my friend Elke and I shared our library of liked songs on Spotify so we could visualize comparisons between our music tastes and then create a model to try and predict whose library a song is in. \nThis blog post will have the following sections:\n\nVisualizing Spotify Data\nStatistical Tests: Prelude to Formal Classification\nSummarizing the classification models \nComparing model performance \nFinal thoughts \n\nNow, let’s dive into the fascinating world of music data analysis and discover whose song it is anyway!"
  },
  {
    "objectID": "posts/2023-03-13-spotify-ML-blog/index.html#introduction",
    "href": "posts/2023-03-13-spotify-ML-blog/index.html#introduction",
    "title": "Whose Song is it Anyway?",
    "section": "",
    "text": "Have you ever wondered how your music taste compares to your friends’? Or perhaps you’re just curious about how your favorite songs and artists and genres stack up against your peers. As a music lover, I enjoy discussing these topics and was thrilled when an assignment for my machine learning course involved analyzing Spotify data. For the assignment, my friend Elke and I shared our library of liked songs on Spotify so we could visualize comparisons between our music tastes and then create a model to try and predict whose library a song is in. \nThis blog post will have the following sections:\n\nVisualizing Spotify Data\nStatistical Tests: Prelude to Formal Classification\nSummarizing the classification models \nComparing model performance \nFinal thoughts \n\nNow, let’s dive into the fascinating world of music data analysis and discover whose song it is anyway!"
  },
  {
    "objectID": "posts/2023-03-13-spotify-ML-blog/index.html#visualizing-spotify-data",
    "href": "posts/2023-03-13-spotify-ML-blog/index.html#visualizing-spotify-data",
    "title": "Whose Song is it Anyway?",
    "section": "Visualizing Spotify Data",
    "text": "Visualizing Spotify Data\nBefore getting started with the modeling, I wanted to explore the patterns of our data visually. Looking at the variables I was able to pull in from the API, I found the following particularly interesting:\n\nAccousticness (0–1):  Whether the track primarily uses instruments that produce sound through acoustic means as opposed to electric or electronic means.\nDanceability (0–1): The ease with which someone can dance to a song based on a combination of musical elements like tempo, rhythm stability, beat strength, and overall regularity.\nEnergy (0–1): Represents a perceptual measure of intensity and activity. Song features that determine the energy score include dynamic range, perceived loudness, timbre, onset rate, and general entropy.\nSpeechiness (0–1): Speechiness detects the presence of spoken words in a track.\nValence (0–1): Describes whether a song’s vibe is positive or negative—tracks with high valence sound more positive (e.g. happy/cheerful), while tracks with low valence sound more negative (e.g. sad/angry).\n\nTo explore which songs in my library have particularly high/low scores for the above metrics, I created an interactive table (and learned that my taste in music is fairly chaotic!).\n\n\nCode\nlibrary(DT)\n\nlewis_liked_tracks %&gt;%\n  dplyr::select(track.name, primary_artist, danceability, acousticness, speechiness, energy, valence) %&gt;%\n  datatable()\n\n\n\n\n\n\nAfter exploring the songs in my library, I transitioned my focus to comparing my music to Elke’s.\n\n\nCode\n#Danceability comparison\ndance_plot &lt;- ggplot(all_tracks, aes(x = danceability, fill = listener,\n                    text = paste(listener))) +\n  geom_density(alpha=0.6, color=NA) +\n  scale_fill_manual(values=c(\"#b0484f\", \"#4436d9\"))+\n  labs(x=\"Danceability\", y=\"Density\") +\n  guides(fill=guide_legend(title=\"Listener\"))+\n  theme_minimal() +\n  ggtitle(\"Distribution of Danceability Data\")\n\n\n#speechiness comparison\nspeech_plot &lt;- ggplot(all_tracks, aes(x = speechiness, fill = listener,\n                    text = paste(listener))) +\n  geom_density(alpha=0.6, color=NA) +\n  scale_fill_manual(values=c(\"#b0484f\", \"#4436d9\"))+\n  labs(x=\"Speechiness\", y=\"Density\") +\n  guides(fill=guide_legend(title=\"Listener\"))+\n  theme_minimal() +\n  ggtitle(\"Distribution of Speechiness Data\")\n\n\n#acousticness comparison\nacoustic_plot &lt;- ggplot(all_tracks, aes(x = acousticness, fill = listener,\n                    text = paste(listener))) +\n  geom_density(alpha=0.6, color=NA) +\n  scale_fill_manual(values=c(\"#b0484f\", \"#4436d9\"))+\n  labs(x=\"Acousticness\", y=\"Density\") +\n  guides(fill=guide_legend(title=\"Listener\"))+\n  theme_minimal() +\n  ggtitle(\"Distribution of Acousticness Data\")\n\n#energy comparison\nenergy_plot &lt;- ggplot(all_tracks, aes(x = energy, fill = listener,\n                    text = paste(listener))) +\n  geom_density(alpha=0.6, color=NA) +\n  scale_fill_manual(values=c(\"#b0484f\", \"#4436d9\"))+\n  labs(x=\"Energy\", y=\"Density\") +\n  guides(fill=guide_legend(title=\"Listener\"))+\n  theme_minimal() +\n  ggtitle(\"Distribution of Energy Data\")\n\nggarrange(dance_plot, speech_plot, acoustic_plot, energy_plot, ncol=2, nrow=2, common.legend = TRUE, legend=\"bottom\")\n\n\n\n\n\n\n\n\n\nA few main takeaways:\n\nBoth Elke and I tend to listen to fairly danceable music, but my library includes more songs that are rated as highly danceable. \nMy library scored much higher in “speechiness” overall — I primarily listen to a mixture of rap and “sad girl” music, so I wasn’t surprised that my library contained more songs with spoken words than Elke’s. \nThe energy in our songs is quite similar, but my library scored a little higher here.\nWhile both of our libraries spanned the full range of acousticness, Elke’s library had more highly acoustic songs while I had more that score very low on this metric. \n\n\n\nCode\n#plotting valence and energy to get a sense for the moods of our liked songs\nggplot(data = all_tracks, aes(x = valence, y = energy, color = listener)) +\n  geom_point(alpha = 0.5) +\n  geom_vline(xintercept = 0.5) +\n  geom_hline(yintercept = 0.5) +\n  scale_x_continuous(expand = c(0, 0), limits = c(0, 1)) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 1)) +\n  annotate('text', 0.25 / 2, 0.95, label = \"Turbulent/Angry\", fontface =\n             \"bold\") +\n  annotate('text', 1.75 / 2, 0.95, label = \"Happy/Joyful\", fontface = \"bold\") +\n  annotate('text', 1.75 / 2, 0.05, label = \"Chill/Peaceful\", fontface =\n             \"bold\") +\n  annotate('text', 0.25 / 2, 0.05, label = \"Sad/Depressing\", fontface =\n             \"bold\") +\n  theme_minimal() +\n  labs(x = \"Valence\",\n       y = \"Energy\",\n       title = \"Plotting songs based on their positivity and energy level\",\n       subtitle = \"Elke and I don't have many songs in the Chill/Peaceful quadrant.\")\n\n\n\n\n\n\n\n\n\nThis above visualization compares the energy and valence of songs. To interpret the plot, it’s important to think about how energy and valence interact. \n\nLow Energy + Low Valence =  Sad / Depressing\nLow Energy + High Valence = Chill / Peaceful\nHigh Energy + High Valence = Happy / Upbeat\nHigh Energy + Low Valence = Turbulent / Angry  \n\nBased on the plot, it looks like neither Elke nor I listen to much chill/peaceful music (which I found somewhat ironic as my most popular playlist on spotify is called “chill”). Aside from this, our music seems to span the graph fairly evenly, although we both listen to music that tends to be a little higher energy. \nTo see which songs represent the various points on this graph, check out an interactive version of the plot below.\n\n\nCode\n## this plotly allows you to hover over points to see the track and the corresponding artist\nplot_ly(data = all_tracks,\n        x = ~valence, \n        y = ~energy, \n        color = ~listener, \n        colors = c(\"#D1999C\", \"#9C8CEC\"),\n        type = \"scatter\", \n        mode = \"markers\",\n        text = paste(\"Track Name:\", all_tracks$track.name, \"&lt;br&gt;\",\n                     \"Primary Artist:\", all_tracks$primary_artist, \"&lt;br&gt;\",\n                     \"Valence:\", all_tracks$valence, \"&lt;br&gt;\", \n                     \"Energy:\", all_tracks$energy, \"&lt;br&gt;\",\n                     \"Listener:\", all_tracks$listener)) %&gt;%\n  layout(xaxis = list(title = \"Valence\"),\n         yaxis = list(title = \"Energy\"),\n         hovermode = \"closest\",\n         title = \"Track Valence vs Energy\")"
  },
  {
    "objectID": "posts/2023-03-13-spotify-ML-blog/index.html#statistical-tests-prelude-to-formal-classification",
    "href": "posts/2023-03-13-spotify-ML-blog/index.html#statistical-tests-prelude-to-formal-classification",
    "title": "Whose Song is it Anyway?",
    "section": "Statistical Tests: Prelude to Formal Classification",
    "text": "Statistical Tests: Prelude to Formal Classification\nTo get an initial sense for whether my classification algorithms might be successful, I decided to run a few t-tests on my variables of interest to see whether my library is different from Elke’s on a statistical level. As can be seen from the tables below, all results were significant at the 0.001 alpha level, suggesting that prediction should be at least somewhat successful.\n\n\nCode\nlibrary(sjPlot)\n\ndance_test_table &lt;- tab_model(t.test(lewis_liked_tracks$danceability, elke_liked_tracks$danceability, var.equal = FALSE),\n          string.ci = c(\"Conf. Int (95%)\"),\n          string.p = \"P-value\",\n          dv.labels = c(\"Danceability Score\"),\n          pred.labels = \"Lewis – Elke\",\n          title = \"Table 1: Comparing Danceability Scores: Welch Two Sample t-test\")\n\ndance_test_table\n\n\n\n\nTable 1: Comparing Danceability Scores: Welch Two Sample t-test\n\n\n \nDanceability Score\n\n\n\nestimate\nConf. Int (95%)\nP-value\nPredictors\n\n\n0.09\n0.07 – 0.10\n&lt;0.001\nLewis – Elke\n\n\n\n\n\n\n\n\nCode\nspeech_test_table &lt;- tab_model(t.test(lewis_liked_tracks$speechiness, elke_liked_tracks$speechiness, var.equal = FALSE),\n          string.ci = c(\"Conf. Int (95%)\"),\n          string.p = \"P-value\",\n          dv.labels = c(\"Speechiness Score\"),\n          pred.labels = \"Lewis – Elke\",\n          title = \"Table 2: Comparing Speechiness Scores: Welch Two Sample t-test\")\n\nspeech_test_table\n\n\n\n\nTable 2: Comparing Speechiness Scores: Welch Two Sample t-test\n\n\n \nSpeechiness Score\n\n\n\nestimate\nConf. Int (95%)\nP-value\nPredictors\n\n\n0.10\n0.09 – 0.11\n&lt;0.001\nLewis – Elke\n\n\n\n\n\n\n\n\nCode\nacoustic_test_table &lt;- tab_model(t.test(lewis_liked_tracks$acousticness, elke_liked_tracks$acousticness, var.equal = FALSE),\n          string.ci = c(\"Conf. Int (95%)\"),\n          string.p = \"P-value\",\n          dv.labels = c(\"Acousticness Score\"),\n          pred.labels = \"Lewis – Elke\",\n          title = \"Table 2: Comparing Acousticness Scores: Welch Two Sample t-test\")\n\nacoustic_test_table\n\n\n\n\nTable 2: Comparing Acousticness Scores: Welch Two Sample t-test\n\n\n \nAcousticness Score\n\n\n\nestimate\nConf. Int (95%)\nP-value\nPredictors\n\n\n-0.13\n-0.16 – -0.09\n&lt;0.001\nLewis – Elke\n\n\n\n\n\n\n\n\nCode\nenergy_test_table &lt;- tab_model(t.test(lewis_liked_tracks$energy, elke_liked_tracks$energy, var.equal = FALSE),\n          string.ci = c(\"Conf. Int (95%)\"),\n          string.p = \"P-value\",\n          dv.labels = c(\"Energy Score\"),\n          pred.labels = \"Lewis – Elke\",\n          title = \"Table 2: Comparing Energy Scores: Welch Two Sample t-test\")\n\nenergy_test_table\n\n\n\n\nTable 2: Comparing Energy Scores: Welch Two Sample t-test\n\n\n \nEnergy Score\n\n\n\nestimate\nConf. Int (95%)\nP-value\nPredictors\n\n\n0.05\n0.03 – 0.07\n&lt;0.001\nLewis – Elke"
  },
  {
    "objectID": "posts/2023-03-13-spotify-ML-blog/index.html#summarizing-the-classification-models",
    "href": "posts/2023-03-13-spotify-ML-blog/index.html#summarizing-the-classification-models",
    "title": "Whose Song is it Anyway?",
    "section": "Summarizing the classification models",
    "text": "Summarizing the classification models\nFor this assignment, we were asked to try a number of different classification methods and compare their results. Here, I used the following methods:\nK-Nearest Neighbors (KNN)\n\nEach observation is predicted based on its ‘similarity’ to other observations. In summary, the algorithm identifies K observations that are “similar” (by some distance metric, often Euclidean or Manhattan) to the new observation being predicted and then uses the average response value (regression) or the most common class (classification) of those K observations as the predicted output.\n\nDecision Tree\n\nA decision support tool that uses a tree-like model of decisions and their possible consequences. Decision trees comprised three main parts: decision nodes (indicating a split), chance nodes (denoting probability), and end nodes (displaying outcomes). Nodes formed recursively using binary partitions by asking simple yes-or-no questions about each feature (e.g. is “acousticness” &lt; 0.4).\n\nBagged Decision Trees (Bagging)\n\nBootstrap aggregating (bagging) prediction models is a general method for fitting multiple versions of a prediction model (such as decision trees) and then combining them into an aggregated prediction. This helps prevent overfitting and reduces the variability in the model; however, when there are dominant predictors, many of the decision trees end up looking very similar (i.e. are highly correlated), which reduces the impact of bagging. \n\nRandom Forests\n\nRandom forests are a modification of bagged decision trees that build a large collection of de-correlated trees to further improve predictive performance. The trees are decorrelated by adding random selection to which predictors are included in individual trees."
  },
  {
    "objectID": "posts/2023-03-13-spotify-ML-blog/index.html#comparing-model-performance",
    "href": "posts/2023-03-13-spotify-ML-blog/index.html#comparing-model-performance",
    "title": "Whose Song is it Anyway?",
    "section": "Comparing model performance",
    "text": "Comparing model performance\nWhen analyzing the performance of a classification model, it’s important to take class imbalance into consideration. On this occasion, 68% of the songs used in the model belong to my Spotify library, so a model that simply predicts “Lewis” as the listener will be correct roughly 68% of the time. Thus, for a model to be deemed at all successful, it would need to obtain an accuracy score above 68%. \nAlong with accuracy, the area under the ROC curve (receiver operating characteristic curve) is commonly used to measure the performance of a classification model. The curve plots the true positive rate on the y axis and the false positive rate on the x axis, and shows the performance of the model at all classification thresholds. A high performing model will have an ROC AUC (area under the curve) score close to 1, indicating that the model is able to detect true positive results while keeping the false positive rate low. \nThe below table and chart demonstrates how well the various models I used performed in terms of accuracy and ROC AUC scores. \n\n\nCode\n#cleaning model metrics to create a table with each model's performance metrics\n\nforest_results_table &lt;- final_forest_fit %&gt;% collect_metrics() %&gt;%\n  dplyr::select(.metric, .estimate) %&gt;%\n  mutate(method = \"Random Forest\")\n\nbagging_results_table &lt;- final_bag_fit %&gt;% collect_metrics() %&gt;%\n  dplyr::select(.metric, .estimate) %&gt;%\n  mutate(method = \"Bagging\")\n\ndecision_tree_results_table &lt;- final_tree_fit %&gt;% collect_metrics() %&gt;%\n  dplyr::select(.metric, .estimate) %&gt;%\n  mutate(method = \"Decision Tree\")\n\nknn_results_table &lt;- final_fit %&gt;% collect_metrics() %&gt;%\n  dplyr::select(.metric, .estimate) %&gt;%\n  mutate(method = \"KNN\")\n\nmajority_class_results_table &lt;- data.frame (.metric  = c(\"accuracy\", \"roc_auc\"),\n                  .estimate = c(nrow(lewis_liked_tracks) / (nrow(lewis_liked_tracks) + nrow(elke_liked_tracks)), .5),\n                  method = c(\"Dummy Classifier\", \"Dummy Classifier\")\n                  )\n\nfull_results &lt;- bind_rows(majority_class_results_table,\n                          knn_results_table,\n                          decision_tree_results_table,\n                          bagging_results_table,\n                          forest_results_table) %&gt;%\n  dplyr::select(method, .estimate, .metric)\n\n#table of results\nfull_results %&gt;%\n  kbl(caption = \"Table 5. Classification Methods and their Respective Accuracies\") %&gt;%\n  kable_classic(full_width = T, html_font = \"Cambria\")\n\n\n\n\nTable 5. Classification Methods and their Respective Accuracies\n\n\nmethod\n.estimate\n.metric\n\n\n\n\nDummy Classifier\n0.6774194\naccuracy\n\n\nDummy Classifier\n0.5000000\nroc_auc\n\n\nKNN\n0.7662651\naccuracy\n\n\nKNN\n0.8254070\nroc_auc\n\n\nDecision Tree\n0.7180723\naccuracy\n\n\nDecision Tree\n0.7515946\nroc_auc\n\n\nBagging\n0.7518072\naccuracy\n\n\nBagging\n0.7981592\nroc_auc\n\n\nRandom Forest\n0.7638554\naccuracy\n\n\nRandom Forest\n0.8089996\nroc_auc\n\n\n\n\n\n\n\n\n\n\nCode\n#accuracy plot\nggplot(data = full_results, aes(x = method, y = .estimate, fill = .metric)) +\n  geom_bar(stat='identity', position='dodge') +\n  theme_minimal() +\n  scale_fill_manual(values=c(\"#9fd182\", \"#7798c9\")) +\n  labs(y = \"Accuracy Estimate\",\n       x = \"Classification Method\",\n       fill = \"Accuracy Metric\",\n       title = \"Random Forest Classification Performed the Best Across Both Accuracy Metrics\")\n\n\n\n\n\n\n\n\n\nThankfully, all of my machine learning models performed better than a dummy classifier (one that always predicts that a song is from my library).\nAcross both performance metrics, the simple decision tree performed the worst out of the models. I believe this is likely due to the class imbalance in the data. Decision trees are “greedy” learners, which means that they don’t think ahead when deciding how to split at any given node.  When one class has low representation, observations can get lost in the majority class nodes and the prediction of the minority class will be even less likely than it should. Essentially, nodes for this decision tree were more likely to contain my songs because my music library is twice as large. For instances where Elke and I listen to similar music, the fact that I have more songs could influence the prediction of the model.\nK-nearest neighbors is also sensitive to class imbalances, as predictions are based solely on the number of similar observations; however, my KNN model outperformed the decision tree model quite substantially with a higher accuracy and much higher ROC AUC. \nThe two ensemble algorithms, bagged decision trees and random forests, performed best on my test data. Random forests outperformed bagging across both accuracy and ROC AUC, making it the best performing model. Due to the class imbalance, it’s likely that many decision trees in the bagging ensemble were highly correlated, so utilizing the random forest approach to decorrelate each individual tree likely helped improve the model efficiency. \nWhile all of the models performed better than a dummy classifier, none were truly exceptional in distinguishing Elke’s liked tracks from mine. When looking at the predictions for each model, I was able to see the percent confidence rate for each prediction—it looked like the models were highly confident when predicting some songs (mainly rap, hip-hop and R&B) from my library, but were much less confident when predicting the alternative/indie music that both Elke and I enjoy."
  },
  {
    "objectID": "posts/2023-03-13-spotify-ML-blog/index.html#final-thoughts",
    "href": "posts/2023-03-13-spotify-ML-blog/index.html#final-thoughts",
    "title": "Whose Song is it Anyway?",
    "section": "Final thoughts",
    "text": "Final thoughts\nOverall, this project was a great opportunity to explore the world of music data analysis and machine learning. It was cool to see the patterns in our music libraries and to compare our tastes on a statistical level. While the results of our classification models were not perfect, they were still quite accurate, and they suggest that there are meaningful differences in the types of songs that Elke and I tend to listen to.\nIf you’re interested in conducting a similar analysis in R, I highly recommend checking out my github repository for this assignment, exploring the Spotify API, and experimenting with the various features and methods available. It’s a great way to gain insight into your own music tastes and to see how they compare to those of your friends and peers."
  },
  {
    "objectID": "posts/2023-01-08-ai-ethics-podcast/index.html",
    "href": "posts/2023-01-08-ai-ethics-podcast/index.html",
    "title": "Ethics of AI and Behavioral Nudging for the Environment",
    "section": "",
    "text": "In this podcast, Elke Windschitl and I discuss the ethics of using behavioral nudging tactics and artificial intelligence to help tackle climate issues. Positions were assigned at random. Elke argued in favor of using AI but against using nudging tactics while I argued the opposing positions.\nThis podcast was created as a final project for EDS 242: Ethics and Bias in Environmental Data Science, an ethics course in UCSB’s Master’s of Environmental Data Science curriculum taught by Dena Montague.\nIntro music was created by Bonfire Records and moderation was conducted by Jessica French.\n\n\n\nelkewind · Debating Nudging and AI for Climate\n\n\n\n\nCitationBibTeX citation:@online{white, elke windschitl2023,\n  author = {White, Elke Windschitl, Lewis},\n  title = {Ethics of {AI} and {Behavioral} {Nudging} for the\n    {Environment}},\n  date = {2023-01-08},\n  url = {https://lewis-r-white.github.io/posts/2023-01-08-ai-ethics-podcast/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nWhite, Elke Windschitl, Lewis. 2023. “Ethics of AI and Behavioral\nNudging for the Environment.” January 8, 2023. https://lewis-r-white.github.io/posts/2023-01-08-ai-ethics-podcast/."
  },
  {
    "objectID": "posts/2022-06-25-pride-article/index.html",
    "href": "posts/2022-06-25-pride-article/index.html",
    "title": "Behind the Scenes of Our LGBTQIA+ Pride Research",
    "section": "",
    "text": "Introduction\nFrom March to June 2022, I had the privilege of working on a research project exploring the thoughts, experiences, and hopes of LGBTQIA+ individuals during Pride month and beyond. While our marketing team’s blog post provides a wonderful overview of the findings, I wanted to share more about the research process we followed and my contributions. Here’s how we drafted our research plan, gathered and analyzed data, and ultimately translated those insights into a meaningful narrative.\n\n\nResearch Goals, Planning, and Survey Drafting\nBefore launching any research project, it’s crucial to clarify our objectives and plan how best to meet them. In this stage, I collaborated with my team to define the project’s key objectives. We focused on understanding the wide range of perspectives from LGBTQIA+ participants about Pride—its current state, its meaning to them, and ways to extend support beyond June—to highlight barriers, intersectional perspectives, and actionable ways for the community and allies to stay engaged year-round.\nWith our research objectives in mind, I drafted the initial set of questions for the unmoderated diary-style research study, then worked with my teammates to refine the surveys into their final version. I also helped ensure that each prompt was open-ended, inclusive, and aligned with our goal of capturing authentic participant stories.\n\n\nParticipant Recruiting\nOnce our objectives were set and our surveys drafted, the next step was finding the right people willing to share their stories. Because we wanted a wide range of experiences, we crafted a screener and selected participants of diverse identities before launching our unmoderated diary study. To ensure we heard from a diverse set of voices, we aimed for participants from various regions, age groups, gender identities, and sexual orientations. We used a screener to recruit self-identified LGBTQIA+ individuals who felt comfortable sharing their experiences and did our best to ensure representation across different subgroups (trans, non-binary, BIPOC, disabled, etc.) to the extent possible. During this phase, I helped finalize the screener questions to ensure we captured the broadest spectrum of identities and perspectives.\n\n\nData Collection\nOnce the participants were selected, we launched our study. The study was broken down into three main sections: identity and expression as a member of the community, how they celebrate Pride and view Pride as an event, and how they would like to see Pride evolve in the future, with each section including its own questionnaire. The research was exploratory so we mostly included open-ended questions and a video question in each section.\nThroughout data collection, I monitored participant engagement, sent deadline reminders, and offered suggestions to improve response quality as needed. This helped the study run smoothly and ensured we received thoughtful, in-depth responses.\n\n\nThematic Tagging and Identifying Representative Quotes\nAfter collecting responses—both text and video—we needed a way to organize and interpret our wealth of qualitative data into coherent themes. This phase involved breaking down each participant entry into representative categories (“tags”) and highlighting standout quotes. To accomplish this, we divided the analysis by section and employed a bottom-up thematic tagging approach, classifying responses to each question into individual themes. For example, for a video question asking respondents to describe what success would look and feel like regarding the future for LGBTQIA+ Americans, the themes “Accept/Normalize Queerness”, “Equal Rights/Opportunities”, and “More Representation” stood out as the most tagged themes.\nAfter each of us tagged our assigned sets of responses, we met to compare our results, refine our themes, and discuss what main takeaways should be included in the article. We then shared our findings with the wonderful Karen Eisenhauer from dscout’s marketing team, who wrote up the final piece shared on dscout’s blog.\n\n\nMy takeaways\nCompleting this project gave me valuable insights into the research process as well as the LGBTQIA+ community’s experiences of Pride. Below are some notes that stuck with me:\n\nInclusive Research Design: Even small changes in question-wording can lead to richer, more genuine participant responses.\nTeam Collaboration: Iterating on questionnaires and tags with my teammates ensured we captured the full breadth of stories.\nOngoing Advocacy: While sharing these insights during Pride Month was wonderful, there’s a need for year-round conversation, visibility, and action.\n\n\n\nReferences\nFor the complete write-up of our findings, including powerful participant quotes and actionable ways to support the LGBTQIA+ community, check out the marketing team’s blog post here.\nCover art taken from OpenUp.\n\n\n\n\nCitationBibTeX citation:@online{white2022,\n  author = {White, Lewis},\n  title = {Behind the {Scenes} of {Our} {LGBTQIA+} {Pride} {Research}},\n  date = {2022-06-25},\n  url = {https://lewis-r-white.github.io/posts/2022-06-25-pride-article/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nWhite, Lewis. 2022. “Behind the Scenes of Our LGBTQIA+ Pride\nResearch.” June 25, 2022. https://lewis-r-white.github.io/posts/2022-06-25-pride-article/."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Bio",
    "section": "",
    "text": "Lewis is a multidisciplinary researcher and data analyst with a background in UX research and environmental data science.\n\nWith over five years of experience in research and data analysis, he specializes in combining qualitative and quantitative methods to uncover insights into human behavior, decision-making, and technology adoption. At dscout, he focused on survey design and qualitative research, supporting clients across industries like healthcare, fitness, and technology. In his current role at Columbia University, he applies quantitative and statistical analysis to research questions at the intersection of environmental health and behavior.\n\nPassionate about employing various research methods to drive meaningful change, Lewis is particularly interested in improving health outcomes, promoting environmental sustainability, and/or enhancing inclusivity in technology and consumer experiences. More broadly, he enjoys exploring the complexities of human decision-making through diverse forms of data—blending statistical analysis with behavioral insights—and collaborating with teammates to uncover meaningful patterns and drive actionable outcomes.\n\nOutside of work, you can find him perfecting his dinks on the pickleball court, experimenting with watercolors, playing strategy board games with friends, and enjoying the great outdoors."
  }
]